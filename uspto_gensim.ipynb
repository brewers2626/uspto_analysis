{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5df9f0c4-5138-4853-b214-95044ec8d955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.7/site-packages (4.2.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from gensim) (6.0.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.7.3)\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f568b7c-855b-42a3-9d11-6f7fe388313a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from collections import Counter\n",
    "import re\n",
    "import time\n",
    "\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# text processing\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff17b05-8102-4301-9bcc-e22919e53396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d8b21b2-7355-4e5a-a81c-24a5963daf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Description of the data fields ---\n",
    "# patent_train and patent_test\n",
    "    # id - unique identifier for a pair of phrases\n",
    "    # anchor - first phrase\n",
    "    # target - second phrase\n",
    "    # context - CPC classification which indicates the context which the similarity is to be scored\n",
    "    # score - similarity between the two phrases\n",
    "    \n",
    "# patent_titles\n",
    "    # code - hierarchical code used to categorize the patent; corresponds to the context field in patent_train and patent_test dataframe\n",
    "    # title - description of the code field\n",
    "    # section - first symbol in the title field; ranges from A - H and Y\n",
    "    # class - 2 digit class\n",
    "    # subclass - 1 letter code subclass\n",
    "    # group - 1-3 digit group code value\n",
    "    # main_group - 2+ sigit main or subgroup after the / symbol\n",
    "    # EXAMPLE: patent_titles.loc[3,'code'] = 'A01B1/00'\n",
    "        # title = 'Hand tools (edge trimmers for lawns A01G3/06  {; machines for working soil A01B35/00; making hand tools B21D})'\n",
    "        # section = A\n",
    "        # class = 1.0\n",
    "        # subclass = B\n",
    "        # group = 1.0\n",
    "        # main_group = 00\n",
    "        \n",
    "# --- Description of the data fields ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e77afa7-a385-4c54-be99-76012a033abd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "feaa3312-3d90-49bd-9a1f-af9dc881c3a7",
   "metadata": {},
   "source": [
    "# Preprocessing of the patents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1acb30-7622-4b28-90fe-a8a926a3d4ef",
   "metadata": {},
   "source": [
    "### Read in the data that has been uploaded to the GCP bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bacfc9e-56f7-4fb3-bc32-304e7e09daed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data from the folder\n",
    "patent_train = pd.read_csv('/home/jupyter/uspto_analysis/train.csv')\n",
    "patent_test = pd.read_csv('/home/jupyter/uspto_analysis/test.csv')\n",
    "patent_titles = pd.read_csv('/home/jupyter/uspto_analysis/titles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95846bc0-d9ff-42eb-919b-6986d17a30d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ea8123c-36e1-40ae-bb0e-e6ffd4e08e34",
   "metadata": {},
   "source": [
    "### Join the training and testing datasets with the titles csv\n",
    "titles.csv contains more information on the context of the patent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eec45fb5-4779-4436-a806-608353dcc80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining the training dataset\n",
    "patents_combined = patent_train.merge(patent_titles, how = 'left', left_on = 'context', right_on = 'code')\n",
    "patents_combined = patents_combined[['id', 'anchor', 'target', 'context', 'title', 'score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29e6d226-0011-4f9c-ae11-24b2db418e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining the testing dataset\n",
    "testing_combined = patent_test.merge(patent_titles, how = 'left', left_on = 'context', right_on = 'code')\n",
    "testing_combined = testing_combined[['id', 'anchor', 'target', 'context', 'title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c81d8888-8909-4354-a552-eb0cc33058f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['anchor', 'target', 'context', 'title', 'score'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a copy of the original dataframe and set the id as the index\n",
    "text_processing_frame = patents_combined.copy()\n",
    "text_processing_frame = text_processing_frame.set_index('id')\n",
    "text_processing_frame.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f3ba59-7ca6-41e5-907b-136763b7a78d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06e1fcb0-085f-4b0c-a86b-679558ed446f",
   "metadata": {},
   "source": [
    "## Processing the text of the patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2be0eb87-dad4-4c04-a872-558623a974a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all of the text fields to lowercase \n",
    "    # anchor, target, and code\n",
    "text_processing_frame['anchor'] = text_processing_frame['anchor'].str.lower()\n",
    "text_processing_frame['target'] = text_processing_frame['target'].str.lower()\n",
    "text_processing_frame['title'] = text_processing_frame['title'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c069e30d-e996-4f09-a534-f1273e6f86af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# remove all non-alphabetic characters from the anchor, target, and title fields\n",
    "text_processing_frame['anchor'] = text_processing_frame.anchor.str.replace('\\W+', ' ')\n",
    "text_processing_frame['target'] = text_processing_frame.target.str.replace('\\W+', ' ')\n",
    "text_processing_frame['title_alpha'] = text_processing_frame.title.str.replace('\\W+', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d9b4342-629b-450e-b847-46864e32f24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization of the data fields\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dc5f503-50bc-4b9b-8068-4dffe0b9e386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the lemmatization function to the text datafields\n",
    "text_processing_frame['lemmatized_anchor'] = text_processing_frame.anchor.apply(lemmatize_text)\n",
    "text_processing_frame['lemmatized_target'] = text_processing_frame.target.apply(lemmatize_text)\n",
    "text_processing_frame['lemmatized_title'] = text_processing_frame.title_alpha.apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20a04030-ccad-41fd-97d5-0edeea341ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new dataframe with the the needed datafields\n",
    "patent_select = pd.DataFrame(text_processing_frame[['lemmatized_anchor','lemmatized_target','lemmatized_title', 'context', 'score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1751ac6-ed12-4d22-8884-d46d501dad35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmatized_anchor</th>\n",
       "      <th>lemmatized_target</th>\n",
       "      <th>lemmatized_title</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37d61fd2272659b1</th>\n",
       "      <td>[abatement]</td>\n",
       "      <td>[abatement, of, pollution]</td>\n",
       "      <td>[furniture, domestic, article, or, appliance, ...</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7b9652b17b68b7a4</th>\n",
       "      <td>[abatement]</td>\n",
       "      <td>[act, of, abating]</td>\n",
       "      <td>[furniture, domestic, article, or, appliance, ...</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36d72442aefd8232</th>\n",
       "      <td>[abatement]</td>\n",
       "      <td>[active, catalyst]</td>\n",
       "      <td>[furniture, domestic, article, or, appliance, ...</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5296b0c19e1ce60e</th>\n",
       "      <td>[abatement]</td>\n",
       "      <td>[eliminating, process]</td>\n",
       "      <td>[furniture, domestic, article, or, appliance, ...</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54c1e3b9184cb5b6</th>\n",
       "      <td>[abatement]</td>\n",
       "      <td>[forest, region]</td>\n",
       "      <td>[furniture, domestic, article, or, appliance, ...</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8e1386cbefd7f245</th>\n",
       "      <td>[wood, article]</td>\n",
       "      <td>[wooden, article]</td>\n",
       "      <td>[decorative, art]</td>\n",
       "      <td>B44</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42d9e032d1cd3242</th>\n",
       "      <td>[wood, article]</td>\n",
       "      <td>[wooden, box]</td>\n",
       "      <td>[decorative, art]</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208654ccb9e14fa3</th>\n",
       "      <td>[wood, article]</td>\n",
       "      <td>[wooden, handle]</td>\n",
       "      <td>[decorative, art]</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756ec035e694722b</th>\n",
       "      <td>[wood, article]</td>\n",
       "      <td>[wooden, material]</td>\n",
       "      <td>[decorative, art]</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8d135da0b55b8c88</th>\n",
       "      <td>[wood, article]</td>\n",
       "      <td>[wooden, substrate]</td>\n",
       "      <td>[decorative, art]</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36473 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 lemmatized_anchor           lemmatized_target  \\\n",
       "id                                                               \n",
       "37d61fd2272659b1       [abatement]  [abatement, of, pollution]   \n",
       "7b9652b17b68b7a4       [abatement]          [act, of, abating]   \n",
       "36d72442aefd8232       [abatement]          [active, catalyst]   \n",
       "5296b0c19e1ce60e       [abatement]      [eliminating, process]   \n",
       "54c1e3b9184cb5b6       [abatement]            [forest, region]   \n",
       "...                            ...                         ...   \n",
       "8e1386cbefd7f245   [wood, article]           [wooden, article]   \n",
       "42d9e032d1cd3242   [wood, article]               [wooden, box]   \n",
       "208654ccb9e14fa3   [wood, article]            [wooden, handle]   \n",
       "756ec035e694722b   [wood, article]          [wooden, material]   \n",
       "8d135da0b55b8c88   [wood, article]         [wooden, substrate]   \n",
       "\n",
       "                                                   lemmatized_title context  \\\n",
       "id                                                                            \n",
       "37d61fd2272659b1  [furniture, domestic, article, or, appliance, ...     A47   \n",
       "7b9652b17b68b7a4  [furniture, domestic, article, or, appliance, ...     A47   \n",
       "36d72442aefd8232  [furniture, domestic, article, or, appliance, ...     A47   \n",
       "5296b0c19e1ce60e  [furniture, domestic, article, or, appliance, ...     A47   \n",
       "54c1e3b9184cb5b6  [furniture, domestic, article, or, appliance, ...     A47   \n",
       "...                                                             ...     ...   \n",
       "8e1386cbefd7f245                                  [decorative, art]     B44   \n",
       "42d9e032d1cd3242                                  [decorative, art]     B44   \n",
       "208654ccb9e14fa3                                  [decorative, art]     B44   \n",
       "756ec035e694722b                                  [decorative, art]     B44   \n",
       "8d135da0b55b8c88                                  [decorative, art]     B44   \n",
       "\n",
       "                  score  \n",
       "id                       \n",
       "37d61fd2272659b1   0.50  \n",
       "7b9652b17b68b7a4   0.75  \n",
       "36d72442aefd8232   0.25  \n",
       "5296b0c19e1ce60e   0.50  \n",
       "54c1e3b9184cb5b6   0.00  \n",
       "...                 ...  \n",
       "8e1386cbefd7f245   1.00  \n",
       "42d9e032d1cd3242   0.50  \n",
       "208654ccb9e14fa3   0.50  \n",
       "756ec035e694722b   0.75  \n",
       "8d135da0b55b8c88   0.50  \n",
       "\n",
       "[36473 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patent_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa01a90-d81c-4a2e-b8dd-174bf1220c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf02c4b1-3979-48d3-ba3b-6771a98df129",
   "metadata": {},
   "source": [
    "### Process to create a word dictionary for further filtering out tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba62beb9-3c22-4d98-be90-0bc7f601238b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of all tokens - lemmatized versions\n",
    "anchor_list = list(text_processing_frame['lemmatized_anchor'])\n",
    "target_list = list(text_processing_frame['lemmatized_target'])\n",
    "title_list = list(text_processing_frame['lemmatized_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d57c97c-5cf7-4de9-a410-b8450e57f240",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_list = (anchor_list + target_list + title_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2faa51c-8e06-4350-a376-60e29c304458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of tokens = 386,751\n",
    "# number of unique tokens\n",
    "    # lemmatization = 8,031\n",
    "all_words = []\n",
    "for item in combined_list:\n",
    "    for word in item:\n",
    "        all_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fdae107-1560-4402-95b4-7a3ca2f78708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386751"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5fc0f59-2ff5-4cb0-b7dc-0396219870f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency of each individual token\n",
    "# convert to a dictionary\n",
    "token_count = FreqDist(all_words)\n",
    "len(token_count)\n",
    "token_list = list(token_count)\n",
    "token_count_dict = dict(token_count)\n",
    "\n",
    "sorted_dict = sorted(token_count_dict.items(), key = lambda x: x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "135159c6-a051-4837-80d1-bf7861ca6408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8031"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cdba541-91ce-43e5-bc05-587e724b4325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of tokens that are to be removed\n",
    "stop_words = list(stopwords.words('english'))\n",
    "token_len_one = [w for w in token_list if len(w) == 1]\n",
    "token_len_two = [w for w in token_list if len(w) == 2]\n",
    "numeric_tokens = [num for num in token_list if any(c.isdigit() for c in num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1a1365c-68d0-4c03-bb33-02d8ab9841ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_len_two"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3c5d40-7b74-41ec-ba67-62c53794c0f9",
   "metadata": {},
   "source": [
    "### EDA - Token Descriptions\n",
    "- lengths for each unique token\n",
    "- avg, max, min, sd of tokens\n",
    "- number of consonants in each token\n",
    "- percentiles of token lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f4611d0-2d21-4d7e-a6fc-c5c3803b46fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of lengths for each of the tokens\n",
    "token_length_list = []\n",
    "for word in token_list:\n",
    "    token_len = len(word)\n",
    "    token_length_list.append(token_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d75d9a89-c3d6-4041-9654-40036a03a2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9313652766188376"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average length of tokens\n",
    "# max length of tokens\n",
    "# standard deviation of tokens\n",
    "avg_token = sum(map(len, token_list))/len(token_list)\n",
    "avg_token\n",
    "max_length = max(token_length_list)\n",
    "max_length\n",
    "token_sd = np.std(token_length_list)\n",
    "token_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5269917-6ca6-450b-894a-b9978f34e213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of consonants in tokens\n",
    "vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "token_data = []\n",
    "for token in token_list:\n",
    "    token_len = len(token)\n",
    "    consonants = 0\n",
    "    for letter in token:\n",
    "        if letter not in vowels:\n",
    "            consonants = consonants + 1\n",
    "    token_data.append((token, token_len, consonants))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c48ff465-7eaa-4a8d-b9e1-98300a7e70f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with metadata about each of the unique tokens\n",
    "token_count_df = pd.DataFrame(token_count_dict.items(), columns = ['token', 'token_count'])\n",
    "token_metadata = pd.DataFrame(token_data, columns = ['token', 'token_length', 'consonant_count'])\n",
    "token_metadata = token_metadata.merge(token_count_df, left_on = 'token', right_on = 'token')\n",
    "token_metadata['consonant_percentage'] = token_metadata['consonant_count']/token_metadata['token_length']\n",
    "\n",
    "high_consonants = token_metadata[token_metadata['consonant_percentage'] > 0.9]\n",
    "consonant_list = list(high_consonants['token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71d8fc1b-3a3e-433b-ae58-195a0b9cd8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for any tokens containing numeric values\n",
    "numeric_tokens = [num for num in token_list if any(c.isdigit() for c in num)]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "659f0c0a-9f88-4b26-b103-9ba700173836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentiles of token lengths\n",
    "twentyfive_percentile = np.percentile(token_length_list, 25)\n",
    "fifty_percentile = np.percentile(token_length_list, 50)\n",
    "sevenfive_percentile = np.percentile(token_length_list, 75)\n",
    "twentyfive_percentile\n",
    "fifty_percentile\n",
    "sevenfive_percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf08631f-7e9d-4198-b652-0b1f61808c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playing around with mean and standard deviation of the token lengths\n",
    "# Testing if long tokens should be removed - NO\n",
    "    # Many important long tokens\n",
    "max_length = max(token_length_list)\n",
    "dictionary_lengths = dict(zip(token_list, token_length_list))\n",
    "\n",
    "sd_value = avg_token + (token_sd *2)\n",
    "sd_value_three = avg_token + (token_sd *3)\n",
    "sd_min = avg_token - (token_sd*2)\n",
    "two_sd = [k for k,v in dictionary_lengths.items() if v >= sd_value]\n",
    "three_sd = [k for k,v in dictionary_lengths.items() if v >= sd_value_three]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a449d63-d1ea-4109-88d2-e59418517c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61e43ca9-27d2-4405-9961-55180646a50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of tokens to be removed\n",
    "remove_list = stop_words + token_len_one + consonant_list + numeric_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52393f8b-87b7-4068-8d97-4b86ffe44074",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_anchor = patent_select['lemmatized_anchor']\n",
    "lemmatized_target = patent_select['lemmatized_target']\n",
    "lemmatized_title = patent_select['lemmatized_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f53a8eb-7fb9-4f5b-89f0-f5cf4f14b8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion to apply the word dictionary to the anchor, target, and title data fields\n",
    "def word_dictionary_apply(patent_datafield):\n",
    "    filter_list = []\n",
    "    for elements in patent_datafield:\n",
    "        inner_filter = []\n",
    "        for token in elements:\n",
    "            if token not in remove_list:\n",
    "                inner_filter.append(token)\n",
    "        filter_list.append(inner_filter)\n",
    "    return filter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e53a366-e0bd-4a99-867c-34fcff6cae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the word dictionary to the specified text fields\n",
    "anchor_filter = word_dictionary_apply(lemmatized_anchor)\n",
    "target_filter = word_dictionary_apply(lemmatized_target)\n",
    "title_filter = word_dictionary_apply(lemmatized_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e362281-e3e3-47dd-90b0-345675c165e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append the text lists to the patent dataframe after the word dictionary has been applied\n",
    "patent_select['anchor_dict'] = anchor_filter\n",
    "patent_select['target_dict'] = target_filter\n",
    "patent_select['title_dict'] = title_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a424f656-5d62-4cdb-aec4-da25755c81f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# future modelling needs input as combined string instead of tokenized text\n",
    "# function to combine the tokenized text fields into a non-tokenized version\n",
    "# add each as a datafield in the dataframe\n",
    "def list_to_string(datafield_list):\n",
    "    string_list = []\n",
    "    for phrase in datafield_list:\n",
    "        new_string = ' '.join(phrase)\n",
    "        string_list.append(new_string)\n",
    "    return string_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3066fb79-f787-4bd2-9cd0-e40262ee8129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function to the tokenized text lists\n",
    "anchor_list = list_to_string(anchor_filter)\n",
    "target_list = list_to_string(target_filter)\n",
    "title_list = list_to_string(title_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee1fd16c-76da-4243-a389-a6a50acb0c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append back to the dataframe\n",
    "patent_select['anchor_list'] = anchor_list\n",
    "patent_select['target_list'] = target_list\n",
    "patent_select['title_list'] = title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad75aea8-db04-4a4d-9803-7f5eb775b617",
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_select = patent_select.drop(columns = ['lemmatized_anchor','lemmatized_target','lemmatized_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66eb6200-a5ec-4da7-9998-8f6a9810bf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new datafield - 'target_title_combined'\n",
    "# concatenate the target and title datafields in order to calculate cosine similarity later on\n",
    "patent_select['target_title_combined'] = patent_select['target_list'] + ' ' + patent_select['title_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "033f4ce2-7e65-417a-80bb-c629985bca6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "37d61fd2272659b1    abatement pollution furniture domestic article...\n",
       "7b9652b17b68b7a4    act abating furniture domestic article applian...\n",
       "36d72442aefd8232    active catalyst furniture domestic article app...\n",
       "5296b0c19e1ce60e    eliminating process furniture domestic article...\n",
       "54c1e3b9184cb5b6    forest region furniture domestic article appli...\n",
       "                                          ...                        \n",
       "8e1386cbefd7f245                        wooden article decorative art\n",
       "42d9e032d1cd3242                            wooden box decorative art\n",
       "208654ccb9e14fa3                         wooden handle decorative art\n",
       "756ec035e694722b                       wooden material decorative art\n",
       "8d135da0b55b8c88                      wooden substrate decorative art\n",
       "Name: target_title_combined, Length: 36473, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patent_select['target_title_combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bc31bd-e894-4524-b085-eb1b68b76b08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "628da37f-7461-491a-802b-37307565c5a3",
   "metadata": {},
   "source": [
    "## Process for tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2166ba10-6b05-43ee-9a50-1d468b6f4550",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_list = list(patent_select['anchor_list'])\n",
    "target_list = list(patent_select['target_list'])\n",
    "title_list = list(patent_select['title_list'])\n",
    "target_title_combined = list(patent_select['target_title_combined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6bcea828-7ad0-41f7-b7be-0ae9d8d067f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_tokenize = []\n",
    "target_tokenize = []\n",
    "title_tokenize = []\n",
    "target_title_tokenize = []\n",
    "for item in anchor_list:\n",
    "    anchor_token = word_tokenize(item)\n",
    "    anchor_tokenize.append(anchor_token)\n",
    "for item in target_list:\n",
    "    target_token = word_tokenize(item)\n",
    "    target_tokenize.append(target_token)\n",
    "for item in title_list:\n",
    "    title_token = word_tokenize(item)\n",
    "    title_tokenize.append(title_tokenize)\n",
    "for item in target_title_combined:\n",
    "    target_title_token = word_tokenize(item)\n",
    "    target_title_tokenize.append(target_title_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0267857d-074e-4277-96ac-65550d2f1bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"patent_select['anchor_tokenize'] = anchor_tokenize\\npatent_select['target_tokenize'] = target_tokenize\\npatent_select['title_tokenize'] = title_tokenize\\npatent_select['target_title_tokenize'] = target_title_tokenize\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''patent_select['anchor_tokenize'] = anchor_tokenize\n",
    "patent_select['target_tokenize'] = target_tokenize\n",
    "patent_select['title_tokenize'] = title_tokenize\n",
    "patent_select['target_title_tokenize'] = target_title_tokenize'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76149739-6810-4213-802b-9aaea3f91857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>anchor_dict</th>\n",
       "      <th>target_dict</th>\n",
       "      <th>title_dict</th>\n",
       "      <th>anchor_list</th>\n",
       "      <th>target_list</th>\n",
       "      <th>title_list</th>\n",
       "      <th>target_title_combined</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37d61fd2272659b1</th>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>[abatement]</td>\n",
       "      <td>[abatement, pollution]</td>\n",
       "      <td>[furniture, domestic, article, appliance, coff...</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abatement pollution</td>\n",
       "      <td>furniture domestic article appliance coffee mi...</td>\n",
       "      <td>abatement pollution furniture domestic article...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7b9652b17b68b7a4</th>\n",
       "      <td>A47</td>\n",
       "      <td>0.75</td>\n",
       "      <td>[abatement]</td>\n",
       "      <td>[act, abating]</td>\n",
       "      <td>[furniture, domestic, article, appliance, coff...</td>\n",
       "      <td>abatement</td>\n",
       "      <td>act abating</td>\n",
       "      <td>furniture domestic article appliance coffee mi...</td>\n",
       "      <td>act abating furniture domestic article applian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36d72442aefd8232</th>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "      <td>[abatement]</td>\n",
       "      <td>[active, catalyst]</td>\n",
       "      <td>[furniture, domestic, article, appliance, coff...</td>\n",
       "      <td>abatement</td>\n",
       "      <td>active catalyst</td>\n",
       "      <td>furniture domestic article appliance coffee mi...</td>\n",
       "      <td>active catalyst furniture domestic article app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5296b0c19e1ce60e</th>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>[abatement]</td>\n",
       "      <td>[eliminating, process]</td>\n",
       "      <td>[furniture, domestic, article, appliance, coff...</td>\n",
       "      <td>abatement</td>\n",
       "      <td>eliminating process</td>\n",
       "      <td>furniture domestic article appliance coffee mi...</td>\n",
       "      <td>eliminating process furniture domestic article...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54c1e3b9184cb5b6</th>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[abatement]</td>\n",
       "      <td>[forest, region]</td>\n",
       "      <td>[furniture, domestic, article, appliance, coff...</td>\n",
       "      <td>abatement</td>\n",
       "      <td>forest region</td>\n",
       "      <td>furniture domestic article appliance coffee mi...</td>\n",
       "      <td>forest region furniture domestic article appli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8e1386cbefd7f245</th>\n",
       "      <td>B44</td>\n",
       "      <td>1.00</td>\n",
       "      <td>[wood, article]</td>\n",
       "      <td>[wooden, article]</td>\n",
       "      <td>[decorative, art]</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden article</td>\n",
       "      <td>decorative art</td>\n",
       "      <td>wooden article decorative art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42d9e032d1cd3242</th>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "      <td>[wood, article]</td>\n",
       "      <td>[wooden, box]</td>\n",
       "      <td>[decorative, art]</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden box</td>\n",
       "      <td>decorative art</td>\n",
       "      <td>wooden box decorative art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208654ccb9e14fa3</th>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "      <td>[wood, article]</td>\n",
       "      <td>[wooden, handle]</td>\n",
       "      <td>[decorative, art]</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden handle</td>\n",
       "      <td>decorative art</td>\n",
       "      <td>wooden handle decorative art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756ec035e694722b</th>\n",
       "      <td>B44</td>\n",
       "      <td>0.75</td>\n",
       "      <td>[wood, article]</td>\n",
       "      <td>[wooden, material]</td>\n",
       "      <td>[decorative, art]</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden material</td>\n",
       "      <td>decorative art</td>\n",
       "      <td>wooden material decorative art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8d135da0b55b8c88</th>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "      <td>[wood, article]</td>\n",
       "      <td>[wooden, substrate]</td>\n",
       "      <td>[decorative, art]</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden substrate</td>\n",
       "      <td>decorative art</td>\n",
       "      <td>wooden substrate decorative art</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36473 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 context  score      anchor_dict             target_dict  \\\n",
       "id                                                                         \n",
       "37d61fd2272659b1     A47   0.50      [abatement]  [abatement, pollution]   \n",
       "7b9652b17b68b7a4     A47   0.75      [abatement]          [act, abating]   \n",
       "36d72442aefd8232     A47   0.25      [abatement]      [active, catalyst]   \n",
       "5296b0c19e1ce60e     A47   0.50      [abatement]  [eliminating, process]   \n",
       "54c1e3b9184cb5b6     A47   0.00      [abatement]        [forest, region]   \n",
       "...                  ...    ...              ...                     ...   \n",
       "8e1386cbefd7f245     B44   1.00  [wood, article]       [wooden, article]   \n",
       "42d9e032d1cd3242     B44   0.50  [wood, article]           [wooden, box]   \n",
       "208654ccb9e14fa3     B44   0.50  [wood, article]        [wooden, handle]   \n",
       "756ec035e694722b     B44   0.75  [wood, article]      [wooden, material]   \n",
       "8d135da0b55b8c88     B44   0.50  [wood, article]     [wooden, substrate]   \n",
       "\n",
       "                                                         title_dict  \\\n",
       "id                                                                    \n",
       "37d61fd2272659b1  [furniture, domestic, article, appliance, coff...   \n",
       "7b9652b17b68b7a4  [furniture, domestic, article, appliance, coff...   \n",
       "36d72442aefd8232  [furniture, domestic, article, appliance, coff...   \n",
       "5296b0c19e1ce60e  [furniture, domestic, article, appliance, coff...   \n",
       "54c1e3b9184cb5b6  [furniture, domestic, article, appliance, coff...   \n",
       "...                                                             ...   \n",
       "8e1386cbefd7f245                                  [decorative, art]   \n",
       "42d9e032d1cd3242                                  [decorative, art]   \n",
       "208654ccb9e14fa3                                  [decorative, art]   \n",
       "756ec035e694722b                                  [decorative, art]   \n",
       "8d135da0b55b8c88                                  [decorative, art]   \n",
       "\n",
       "                   anchor_list          target_list  \\\n",
       "id                                                    \n",
       "37d61fd2272659b1     abatement  abatement pollution   \n",
       "7b9652b17b68b7a4     abatement          act abating   \n",
       "36d72442aefd8232     abatement      active catalyst   \n",
       "5296b0c19e1ce60e     abatement  eliminating process   \n",
       "54c1e3b9184cb5b6     abatement        forest region   \n",
       "...                        ...                  ...   \n",
       "8e1386cbefd7f245  wood article       wooden article   \n",
       "42d9e032d1cd3242  wood article           wooden box   \n",
       "208654ccb9e14fa3  wood article        wooden handle   \n",
       "756ec035e694722b  wood article      wooden material   \n",
       "8d135da0b55b8c88  wood article     wooden substrate   \n",
       "\n",
       "                                                         title_list  \\\n",
       "id                                                                    \n",
       "37d61fd2272659b1  furniture domestic article appliance coffee mi...   \n",
       "7b9652b17b68b7a4  furniture domestic article appliance coffee mi...   \n",
       "36d72442aefd8232  furniture domestic article appliance coffee mi...   \n",
       "5296b0c19e1ce60e  furniture domestic article appliance coffee mi...   \n",
       "54c1e3b9184cb5b6  furniture domestic article appliance coffee mi...   \n",
       "...                                                             ...   \n",
       "8e1386cbefd7f245                                     decorative art   \n",
       "42d9e032d1cd3242                                     decorative art   \n",
       "208654ccb9e14fa3                                     decorative art   \n",
       "756ec035e694722b                                     decorative art   \n",
       "8d135da0b55b8c88                                     decorative art   \n",
       "\n",
       "                                              target_title_combined  \n",
       "id                                                                   \n",
       "37d61fd2272659b1  abatement pollution furniture domestic article...  \n",
       "7b9652b17b68b7a4  act abating furniture domestic article applian...  \n",
       "36d72442aefd8232  active catalyst furniture domestic article app...  \n",
       "5296b0c19e1ce60e  eliminating process furniture domestic article...  \n",
       "54c1e3b9184cb5b6  forest region furniture domestic article appli...  \n",
       "...                                                             ...  \n",
       "8e1386cbefd7f245                      wooden article decorative art  \n",
       "42d9e032d1cd3242                          wooden box decorative art  \n",
       "208654ccb9e14fa3                       wooden handle decorative art  \n",
       "756ec035e694722b                     wooden material decorative art  \n",
       "8d135da0b55b8c88                    wooden substrate decorative art  \n",
       "\n",
       "[36473 rows x 9 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patent_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9237eb0a-a134-422d-a99d-0bdad00075a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abatement']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_tokenize[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0b00fd-e104-4406-97f3-0ab74fd841a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d46f0e5c-4464-4f3d-8e45-978d5c88aef8",
   "metadata": {},
   "source": [
    "# Implementation of the Gensim module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ce5d19-75ce-41d7-a1a4-b3ca2b5314ff",
   "metadata": {},
   "source": [
    "### Determining the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37f21379-a4ad-4845-a65e-28bb218d0ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of topics - how many context labels exist in the dataset?\n",
    "num_titles = len(pd.unique(patent_titles['section']))\n",
    "num_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "34d5ded8-1bf6-4bcb-829e-63b252f2d82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>title</th>\n",
       "      <th>section</th>\n",
       "      <th>class</th>\n",
       "      <th>subclass</th>\n",
       "      <th>group</th>\n",
       "      <th>main_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>HUMAN NECESSITIES</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A01</td>\n",
       "      <td>AGRICULTURE; FORESTRY; ANIMAL HUSBANDRY; HUNTI...</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A01B</td>\n",
       "      <td>SOIL WORKING IN AGRICULTURE OR FORESTRY; PARTS...</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A01B1/00</td>\n",
       "      <td>Hand tools (edge trimmers for lawns A01G3/06  ...</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A01B1/02</td>\n",
       "      <td>Spades; Shovels {(hand-operated dredgers E02F3...</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260471</th>\n",
       "      <td>Y10T483/1864</td>\n",
       "      <td>including tool pot or adapter</td>\n",
       "      <td>Y</td>\n",
       "      <td>10.0</td>\n",
       "      <td>T</td>\n",
       "      <td>483.0</td>\n",
       "      <td>1864.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260472</th>\n",
       "      <td>Y10T483/1873</td>\n",
       "      <td>Indexing matrix</td>\n",
       "      <td>Y</td>\n",
       "      <td>10.0</td>\n",
       "      <td>T</td>\n",
       "      <td>483.0</td>\n",
       "      <td>1873.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260473</th>\n",
       "      <td>Y10T483/1882</td>\n",
       "      <td>Rotary disc</td>\n",
       "      <td>Y</td>\n",
       "      <td>10.0</td>\n",
       "      <td>T</td>\n",
       "      <td>483.0</td>\n",
       "      <td>1882.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260474</th>\n",
       "      <td>Y10T483/1891</td>\n",
       "      <td>Chain or belt</td>\n",
       "      <td>Y</td>\n",
       "      <td>10.0</td>\n",
       "      <td>T</td>\n",
       "      <td>483.0</td>\n",
       "      <td>1891.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260475</th>\n",
       "      <td>Y10T483/19</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>Y</td>\n",
       "      <td>10.0</td>\n",
       "      <td>T</td>\n",
       "      <td>483.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260476 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                code                                              title  \\\n",
       "0                  A                                  HUMAN NECESSITIES   \n",
       "1                A01  AGRICULTURE; FORESTRY; ANIMAL HUSBANDRY; HUNTI...   \n",
       "2               A01B  SOIL WORKING IN AGRICULTURE OR FORESTRY; PARTS...   \n",
       "3           A01B1/00  Hand tools (edge trimmers for lawns A01G3/06  ...   \n",
       "4           A01B1/02  Spades; Shovels {(hand-operated dredgers E02F3...   \n",
       "...              ...                                                ...   \n",
       "260471  Y10T483/1864                      including tool pot or adapter   \n",
       "260472  Y10T483/1873                                    Indexing matrix   \n",
       "260473  Y10T483/1882                                        Rotary disc   \n",
       "260474  Y10T483/1891                                      Chain or belt   \n",
       "260475    Y10T483/19                                      Miscellaneous   \n",
       "\n",
       "       section  class subclass  group  main_group  \n",
       "0            A    NaN      NaN    NaN         NaN  \n",
       "1            A    1.0      NaN    NaN         NaN  \n",
       "2            A    1.0        B    NaN         NaN  \n",
       "3            A    1.0        B    1.0         0.0  \n",
       "4            A    1.0        B    1.0         2.0  \n",
       "...        ...    ...      ...    ...         ...  \n",
       "260471       Y   10.0        T  483.0      1864.0  \n",
       "260472       Y   10.0        T  483.0      1873.0  \n",
       "260473       Y   10.0        T  483.0      1882.0  \n",
       "260474       Y   10.0        T  483.0      1891.0  \n",
       "260475       Y   10.0        T  483.0        19.0  \n",
       "\n",
       "[260476 rows x 7 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patent_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55a6ee2-4401-415e-a3e3-8bc48c01e8e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "28099ad2-801c-4f10-bad8-fac542217711",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patents = anchor_list + target_title_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3edb766b-e859-4cdf-a38b-571156fe4d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patent_process = [simple_preprocess(item) for item in all_patents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a130e3fe-212f-4c9a-9825-ca8df139a52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(d, [i]) for i, d in enumerate(all_patent_process)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1a2e6e4b-9e37-489a-96cb-917a3a1caa6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72946"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "036d3df8-c407-4822-86a2-651135226ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['abatement'], tags=[0])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "738c4598-8ba7-41a2-8d94-3281eac2e151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the hyperparameters to be used for the doc2vec model\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size = 500, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb1ed9c-1359-4a2f-a90e-5079d6fc68dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "79fd9d5e-9e46-464e-a1e2-b879b74bce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "882e2b2e-bd1e-45be-9e4b-5e09143acfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'abatement' appeared 63 times in the training corpus.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Word 'abatement' appeared {model.wv.get_vecattr('abatement', 'count')} times in the training corpus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1eba2c71-b562-4b46-87cb-3c7b881bd4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time (minutes) to train doc2vec:  5.220850129922231\n"
     ]
    }
   ],
   "source": [
    "# train the doc2vec model\n",
    "\n",
    "start = time.time()\n",
    "model.train(tagged_data, total_examples = model.corpus_count, epochs = model.epochs)\n",
    "print('time (minutes) to train doc2vec: ', (time.time()-start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e90980-6c81-4620-8d3a-cd66271a48da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dae013e0-4599-4ec2-b4e2-fba76b74ddfc",
   "metadata": {},
   "source": [
    "## Testing the model on a few sample patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e3e8aa26-d01d-45b2-a9f8-5462e7191fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test cosine similarity\n",
    "    # anchor 1 = abnormal position\n",
    "    # target/title 1 = abnormal breathing/weaving\n",
    "    # score 1 = 0\n",
    "    # anchor 2 = abnormal position\n",
    "    # target/title 2 = abnormal placemenet/weaving\n",
    "    # score 2 = 0.75\n",
    "train_anchor = anchor_list[71]\n",
    "train_combined = target_title_combined[71]\n",
    "train_anchor2 = anchor_list[73]\n",
    "train_combined2 = target_title_combined[73]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "eac26e53-8d72-4029-98a0-61568499c05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abnormal breathing weaving'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ff461237-fee1-4119-9ae9-5ae4972831ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_vec1 = model.infer_vector(train_anchor.split())\n",
    "combined_vec1 = model.infer_vector(train_anchor.split())\n",
    "anchor_vec2 = model.infer_vector(train_anchor2.split())\n",
    "combined_vec2 = model.infer_vector(train_combined2.split())\n",
    "\n",
    "anchor_vec1 = anchor_vec1.reshape(1, -1)\n",
    "combined_vec1 = combined_vec1.reshape(1, -1)\n",
    "anchor_vec2 = anchor_vec2.reshape(1, -1)\n",
    "combined_vec2 = combined_vec2.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "38f0c52d-26e9-4221-af7f-ac1ff4c88657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97753304]], dtype=float32)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_distance1 = cosine_similarity(anchor_vec1, combined_vec1)\n",
    "cos_distance1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a76f7f22-d09f-4fda-9560-59474cb2e528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42563236]], dtype=float32)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_distance2 = cosine_similarity(anchor_vec2, combined_vec2)\n",
    "cos_distance2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ac359426-292c-47bc-bf16-31311fa19e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.doc2vec.Doc2Vec at 0x7fdcc5ed8f50>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e2556a7-3b21-4b54-bc18-5544dd232689",
   "metadata": {},
   "source": [
    "# Score the Doc2Vec model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "890577dc-2366-4e62-9910-77b5144642b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_score_list = []\n",
    "for i in range(len(patent_select)):\n",
    "    patent_anchor = anchor_list[i]\n",
    "    patent_combined = target_title_combined[i]\n",
    "    patent_anchor_vec = model.infer_vector(patent_anchor.split())\n",
    "    patent_anchor_vec = patent_anchor_vec.reshape(1, -1)\n",
    "    patent_combined_vec = model.infer_vector(patent_combined.split())\n",
    "    patent_combined_vec = patent_combined_vec.reshape(1, -1)\n",
    "    cos_distance = cosine_similarity(patent_anchor_vec, patent_combined_vec)\n",
    "    cosine_score_list.append(cos_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "58f04271-0b87-427e-b6d1-ae9834bd427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_list = []\n",
    "for i in range(len(cosine_score_list)):\n",
    "    test_list = np.array2string(cosine_score_list[i][0][0])\n",
    "    cosine_list.append(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3eb1509c-8df5-4008-9c85-e06ddb147b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_list = [float(i) for i in cosine_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "505410f4-08e1-42a5-af33-442bc66216c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98755324"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(cosine_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bb01c1f7-2139-46cd-a6a8-21032a86ab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_positive = []\n",
    "for val in cosine_list:\n",
    "    pos_val = val + 1\n",
    "    cosine_positive.append(pos_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a6b565b0-3132-4dc9-931f-c42d895284ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.98755324"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(cosine_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "496a9e3c-9b6b-4194-b793-78a1b4467eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_cosine = [cos_val/max(cosine_positive) for cos_val in cosine_positive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4fae28aa-fe18-4d38-8c5e-309184d853ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(normalized_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c90e077-156b-43da-9c73-2fe9e71315c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "99ced323-9d79-4959-8592-c6a40161d208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to round output to nearest quarter decimal for submission\n",
    "def quarter_round(cosine_list, round_val):\n",
    "    cosine_round = []\n",
    "    for num in cosine_list:\n",
    "        num_rounded = round(num/round_val) * round_val\n",
    "        cosine_round.append(num_rounded)\n",
    "    return cosine_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a1247b6c-18a8-4f24-860a-ebea814ca6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_rounded = quarter_round(normalized_cosine, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c5a196-8a30-4d31-b5d6-717a66d701b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c0bc6bda-307f-42ad-82ec-285f23eb0a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "training_eval = patent_select[['score']]\n",
    "training_eval['model_score'] = cosine_rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "613596f3-29cc-4768-a4d9-fc4518665b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "training_eval['correct_results'] = np.where(training_eval['score'] == training_eval['model_score'], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ec587879-45f8-4ac7-9c71-8491bf7347db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "training_eval['difference'] = abs(training_eval['model_score'] - training_eval['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "848e7ea0-a8cd-4caf-98f9-d606f86f8785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>model_score</th>\n",
       "      <th>correct_results</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37d61fd2272659b1</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7b9652b17b68b7a4</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36d72442aefd8232</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5296b0c19e1ce60e</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54c1e3b9184cb5b6</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8e1386cbefd7f245</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42d9e032d1cd3242</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208654ccb9e14fa3</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756ec035e694722b</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8d135da0b55b8c88</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36473 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  score  model_score  correct_results  difference\n",
       "id                                                               \n",
       "37d61fd2272659b1   0.50         0.75                0        0.25\n",
       "7b9652b17b68b7a4   0.75         0.75                1        0.00\n",
       "36d72442aefd8232   0.25         0.50                0        0.25\n",
       "5296b0c19e1ce60e   0.50         0.75                0        0.25\n",
       "54c1e3b9184cb5b6   0.00         0.75                0        0.75\n",
       "...                 ...          ...              ...         ...\n",
       "8e1386cbefd7f245   1.00         0.75                0        0.25\n",
       "42d9e032d1cd3242   0.50         0.75                0        0.25\n",
       "208654ccb9e14fa3   0.50         0.75                0        0.25\n",
       "756ec035e694722b   0.75         0.50                0        0.25\n",
       "8d135da0b55b8c88   0.50         0.75                0        0.25\n",
       "\n",
       "[36473 rows x 4 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1f62b93e-f725-4657-a40d-8196fabe96ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19650152167356674"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percent predicted correctly\n",
    "training_eval.sum(axis = 0)[2]/len(training_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e06678dc-2f14-43b9-9306-8c159ab1f972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>model_score</th>\n",
       "      <th>correct_results</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>difference</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>7308</td>\n",
       "      <td>7308</td>\n",
       "      <td>7308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>13113</td>\n",
       "      <td>13113</td>\n",
       "      <td>13113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>10087</td>\n",
       "      <td>10087</td>\n",
       "      <td>10087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>4947</td>\n",
       "      <td>4947</td>\n",
       "      <td>4947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>1018</td>\n",
       "      <td>1018</td>\n",
       "      <td>1018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            score  model_score  correct_results\n",
       "difference                                     \n",
       "0.00         7308         7308             7308\n",
       "0.25        13113        13113            13113\n",
       "0.50        10087        10087            10087\n",
       "0.75         4947         4947             4947\n",
       "1.00         1018         1018             1018"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_eval.groupby('difference').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2baa682f-d9ac-4c76-b059-349b194e802d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36473"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e509fda-1b60-404e-a594-624fc27f20e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "093b9675-0371-405d-8ce0-2951f83b0e62",
   "metadata": {},
   "source": [
    "# Improving Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc911777-bf69-49fa-afb8-347443bc5127",
   "metadata": {},
   "source": [
    "### Testing out different hyperparameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64707973-67bc-448f-94bd-d9d084779991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating through different combinations of vector_size and epoch values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db948c3e-2d4d-4e0d-916e-c052e496eb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = tagged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4dc8fa-44f8-4581-84b8-92a450bced15",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_values = [200, 400, 500]\n",
    "num_epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f37848-d2b6-4069-a53c-7ddf610a9d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "for values in vec_values:\n",
    "    model = gensim.models.doc2vec.Doc2Vec(vector_size = values, epochs = num_epochs)\n",
    "    model.build_vocab(tagged_data)\n",
    "    model.train(tagged_data, total_examples = model.corpus_count, epochs = model.epochs)\n",
    "    cosine_score_list = []\n",
    "    for i in range(len(patent_select)):\n",
    "        patent_anchor = anchor_list[i]\n",
    "        patent_combined = target_title_combined[i]\n",
    "        patent_anchor_vec = model.infer_vector(patent_anchor.split())\n",
    "        patent_anchor_vec = patent_anchor_vec.reshape(1, -1)\n",
    "        patent_combined_vec = model.infer_vector(patent_combined.split())\n",
    "        patent_combined_vec = patent_combined_vec.reshape(1, -1)\n",
    "        cos_distance = cosine_similarity(patent_anchor_vec, patent_combined_vec)\n",
    "        cosine_score_list.append(cos_distance)\n",
    "print('time(minutes) to run models: ', , (time.time()-start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468e9709-8913-4aad-95c0-528a41132fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1 = cosine_score_list[0]\n",
    "vec2 = cosine_score_list[1]\n",
    "vec3 = cosine_score_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a14f1e-589f-4927-9673-24907b0c1b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vecs = []\n",
    "for vec in cosine_score_list:\n",
    "    cosine_list = []\n",
    "    for i in range(len(vec)):\n",
    "        test_list = np.array2string(cosine_score_list[i][0][0])\n",
    "        cosine_list.append(test_list)\n",
    "    all_vecs.append(cosine_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f885e19-51de-411e-baba-88dda98db839",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_cosine = []\n",
    "for cosine_vals in all_vecs:\n",
    "    cosine_list = [float(i) for i in cosine_vals]\n",
    "    float_cosine.append(cosine_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ebee00-a766-4ff0-9725-ddd3a14c6c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_cosine2 = []\n",
    "for float_cosine1 in float_cosine:\n",
    "    cosine_positive = []\n",
    "    for val in cosine_list:\n",
    "        pos_val = val + 1\n",
    "        cosine_positive.append(pos_val)\n",
    "    float_cosine2.append(cosine_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b302bed-4a03-4714-ac5c-4bc2f7b06670",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_normalized = []\n",
    "for positive in float_cosine2:\n",
    "    normalized_cosine = [cos_val/max(positive) for cos_val in positive]\n",
    "    cosine_normalized.append(normalized_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b4de25-4ec2-4826-ac9f-22d0ef6fcfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_cosine = []\n",
    "for normalized_list in cosine_normalized:\n",
    "    cosine_rounded = quarter_round(normalized_list, 0.25)\n",
    "    rounded_cosine.append(cosine_rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d00a9a-3f61-4081-a9c9-95dd9672c7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8939c5f7-874c-4b5f-a120-1c1f5c48ee62",
   "metadata": {},
   "source": [
    "# Processing and Handling on the Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6263afbf-6671-4f99-9f03-45f5d1e4c492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['anchor', 'target', 'context', 'title'], dtype='object')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a copy of the original dataframe and set the id as the index\n",
    "text_processing_frame = testing_combined.copy()\n",
    "text_processing_frame = text_processing_frame.set_index('id')\n",
    "text_processing_frame.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4fca3aee-6846-4234-9e92-e2153a0b1516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 4)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_processing_frame.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3656326c-a99f-4df7-b5f3-3d9ce722fce3",
   "metadata": {},
   "source": [
    "## Processing the text of the patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "bda89cae-2a47-472c-a75b-d363a2e70d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all of the text fields to lowercase \n",
    "    # anchor, target, and code\n",
    "text_processing_frame['anchor'] = text_processing_frame['anchor'].str.lower()\n",
    "text_processing_frame['target'] = text_processing_frame['target'].str.lower()\n",
    "text_processing_frame['title'] = text_processing_frame['title'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "abfb5945-d656-4d69-b571-3b70b432d52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# remove all non-alphabetic characters from the anchor, target, and title fields\n",
    "text_processing_frame['anchor'] = text_processing_frame.anchor.str.replace('\\W+', ' ')\n",
    "text_processing_frame['target'] = text_processing_frame.target.str.replace('\\W+', ' ')\n",
    "text_processing_frame['title_alpha'] = text_processing_frame.title.str.replace('\\W+', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "acbce350-b381-4591-b95d-36f20f10d2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization of the data fields\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c794e41b-549a-4c2b-bbb7-d1f1c7dc8661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the lemmatization function to the text datafields\n",
    "text_processing_frame['lemmatized_anchor'] = text_processing_frame.anchor.apply(lemmatize_text)\n",
    "text_processing_frame['lemmatized_target'] = text_processing_frame.target.apply(lemmatize_text)\n",
    "text_processing_frame['lemmatized_title'] = text_processing_frame.title_alpha.apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "39609e86-59f9-4839-9fb7-8647a6089c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['anchor', 'target', 'context', 'title', 'title_alpha',\n",
       "       'lemmatized_anchor', 'lemmatized_target', 'lemmatized_title'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_processing_frame.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1e61075d-f0f2-44e4-994e-947cc6bd929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new dataframe with the the needed datafields\n",
    "patent_select = pd.DataFrame(text_processing_frame[['lemmatized_anchor','lemmatized_target','lemmatized_title', 'context']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4630ba-1939-4337-8758-1c7f3e67eaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "48e5205b-539c-48d5-9ef3-135fc0581e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_anchor = patent_select['lemmatized_anchor']\n",
    "lemmatized_target = patent_select['lemmatized_target']\n",
    "lemmatized_title = patent_select['lemmatized_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "10bdf60c-133c-4418-a1f7-8fb95d482095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the word dictionary to the specified text fields\n",
    "anchor_filter = word_dictionary_apply(lemmatized_anchor)\n",
    "target_filter = word_dictionary_apply(lemmatized_target)\n",
    "title_filter = word_dictionary_apply(lemmatized_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18340252-0f66-48d1-9a6e-280781c94e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "87b1bb25-1e7c-4732-9410-d455654dc6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append the text lists to the patent dataframe after the word dictionary has been applied\n",
    "patent_select['anchor_dict'] = anchor_filter\n",
    "patent_select['target_dict'] = target_filter\n",
    "patent_select['title_dict'] = title_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "47933752-49b4-4761-b73e-413495e7a79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function to the tokenized text lists\n",
    "anchor_list = list_to_string(anchor_filter)\n",
    "target_list = list_to_string(target_filter)\n",
    "title_list = list_to_string(title_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0d033e20-577f-414e-88f9-a4f078966c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append back to the dataframe\n",
    "patent_select['anchor_list'] = anchor_list\n",
    "patent_select['target_list'] = target_list\n",
    "patent_select['title_list'] = title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "897cbe06-d186-4c45-9294-6425495a2251",
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_select = patent_select.drop(columns = ['lemmatized_anchor','lemmatized_target','lemmatized_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "42a85e85-818b-4c04-8bf8-02cd710b8e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new datafield - 'target_title_combined'\n",
    "# concatenate the target and title datafields in order to calculate cosine similarity later on\n",
    "patent_select['target_title_combined'] = patent_select['target_list'] + ' ' + patent_select['title_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "71d6e20a-5cbe-433a-928c-81945cad14d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['context', 'anchor_dict', 'target_dict', 'title_dict', 'anchor_list',\n",
       "       'target_list', 'title_list', 'target_title_combined'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patent_select.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "04444d95-95c0-4e24-bf53-b2263e59e3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_list = list(patent_select['anchor_list'])\n",
    "target_list = list(patent_select['target_list'])\n",
    "title_list = list(patent_select['title_list'])\n",
    "target_title_combined = list(patent_select['target_title_combined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e8463a7f-5d8b-4b5c-b8ec-b2af10231a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_score_list = []\n",
    "for i in range(len(patent_select)):\n",
    "    patent_anchor = anchor_list[i]\n",
    "    patent_combined = target_title_combined[i]\n",
    "    patent_anchor_vec = model.infer_vector(patent_anchor.split())\n",
    "    patent_anchor_vec = patent_anchor_vec.reshape(1, -1)\n",
    "    patent_combined_vec = model.infer_vector(patent_combined.split())\n",
    "    patent_combined_vec = patent_combined_vec.reshape(1, -1)\n",
    "    cos_distance = cosine_similarity(patent_anchor_vec, patent_combined_vec)\n",
    "    cosine_score_list.append(cos_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9380c48-2a14-4e62-8872-8acd4dcf8017",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4ef73abf-b957-47a4-bb76-7b680e995155",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_list = []\n",
    "for i in range(len(cosine_score_list)):\n",
    "    test_list = np.array2string(cosine_score_list[i][0][0])\n",
    "    cosine_list.append(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "cfb9c441-4e0a-4747-b3ab-fef97c24bfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_list = [float(i) for i in cosine_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4feaba58-1dba-4c5a-bf40-77381915867e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5176584"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(cosine_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a8d68d2f-b85e-42f6-9276-e3d9f8ce9d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_positive = []\n",
    "for val in cosine_list:\n",
    "    pos_val = val + 1\n",
    "    cosine_positive.append(pos_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0da17bd3-0ef3-4c18-8941-2557b4c7e9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48234160000000004"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(cosine_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7671a0e4-23f5-401c-b8e7-eda727c32bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_cosine = [cos_val/max(cosine_positive) for cos_val in cosine_positive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "172e2f29-631b-49b0-9422-063a183417d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(normalized_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "671a1066-6121-4823-bea1-19ad3f7e4d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_rounded = quarter_round(normalized_cosine, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee600c52-3f44-4d89-a3c9-f6db9fe1f859",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51448ff7-b05e-4ed0-8353-0ecf4969243a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b15d32-8e66-4b67-8f4b-f17b12b13705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8ee6048-5f99-43d3-bc5f-5c3a42bdbcc9",
   "metadata": {},
   "source": [
    "# Put together file for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a5d50c09-2f9c-4fd1-9a8c-996f3e5d77d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_ids = list(testing_combined['id'])\n",
    "submission_df = pd.DataFrame(list(zip(testing_ids, cosine_rounded)), columns = ['id', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7497ffc7-bbd8-4c4e-b6c8-203379f65c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('/home/jupyter/uspto_analysis/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "27c2a35f-a257-4400-bf3e-c180f788ee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3b8e19c6-9340-4f39-838a-e42522a2d69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write pandas df to GCP \n",
    "client = storage.Client()\n",
    "bucket = client.get_bucket('cliffm_uspto_kaggle_data')\n",
    "    \n",
    "bucket.blob('submission.csv').upload_from_string(submission_df.to_csv(), 'text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3233114-1622-4b77-af86-bc3237d87e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54fe76e-b833-46eb-889f-27298098f19e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13be7e7b-375e-4b47-861f-6eb75c59e504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process for stemming the content of the patents\n",
    "# Too aggressive for my liking\n",
    "# Worse performance when calculating the cosine similarity between the patents later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eecae5d-17d4-4a50-8488-5202a1fad298",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "stemmer = PorterStemmer()\n",
    "def stemmer_text(text_field):\n",
    "    return [stemmer.stem(w) for w in word_tokenize(text_field)]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc90cf8e-bbfa-4f12-aa44-8b02b0bdb33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "text_processing_frame['stemmed_anchor'] = text_processing_frame.anchor.apply(stemmer_text)\n",
    "text_processing_frame['stemmed_target'] = text_processing_frame.target.apply(stemmer_text)\n",
    "text_processing_frame['stemmed_title'] = text_processing_frame.title_alpha.apply(stemmer_text)\n",
    "\n",
    "\n",
    "patent_select = pd.DataFrame(text_processing_frame[['lemmatized_anchor', 'lemmatized_target', 'lemmatized_title', 'code', 'score']])\n",
    "patent_select = pd.DataFrame(text_processing_frame[['stemmed_anchor', 'stemmed_target', 'stemmed_title', 'code', 'score']])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0332c6c7-8ad5-4114-8b1a-4d148f28c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# create list of all tokens - stemmed versions\n",
    "anchor_list = list(text_processing_frame['stemmed_anchor'])\n",
    "target_list = list(text_processing_frame['stemmed_target'])\n",
    "title_list = list(text_processing_frame['stemmed_title'])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5829bcf0-e55a-43bc-b2f8-ea6d41c03078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f992dfc-7a9d-442c-a159-4e4e013149ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Patent EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d29dd6-bf52-4d2e-b403-8fee958bae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Description of the data fields ---\n",
    "# patent_train and patent_test\n",
    "    # id - unique identifier for a pair of phrases\n",
    "    # anchor - first phrase\n",
    "    # target - second phrase\n",
    "    # context - CPC classification which indicates the context which the similarity is to be scored\n",
    "    # score - similarity between the two phrases\n",
    "    \n",
    "# patent_titles\n",
    "    # code - hierarchical code used to categorize the patent; corresponds to the context field in patent_train and patent_test dataframe\n",
    "    # title - description of the code field\n",
    "    # section - first symbol in the title field; ranges from A - H and Y\n",
    "    # class - 2 digit class\n",
    "    # subclass - 1 letter code subclass\n",
    "    # group - 1-3 digit group code value\n",
    "    # main_group - 2+ sigit main or subgroup after the / symbol\n",
    "    # EXAMPLE: patent_titles.loc[3,'code'] = 'A01B1/00'\n",
    "        # title = 'Hand tools (edge trimmers for lawns A01G3/06  {; machines for working soil A01B35/00; making hand tools B21D})'\n",
    "        # section = A\n",
    "        # class = 1.0\n",
    "        # subclass = B\n",
    "        # group = 1.0\n",
    "        # main_group = 00\n",
    "        \n",
    "# --- Description of the data fields ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff0f3d8e-40e1-4c8f-a1bc-1d95347bbe95",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'patent_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1495/456798647.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpatent_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpatent_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpatent_titles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# patent_cpc.head()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'patent_train' is not defined"
     ]
    }
   ],
   "source": [
    "patent_train.head()\n",
    "patent_test.head()\n",
    "# patent_titles.head()\n",
    "# patent_cpc.head()\n",
    "\n",
    "patent_train.shape\n",
    "\n",
    "# data fields\n",
    "patent_train.columns\n",
    "patent_titles.columns\n",
    "# patent_cpc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db0ee59a-d7a0-4968-950a-ce748bab5737",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'patent_titles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1495/2770413327.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcol_data_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mpatent_titles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mview_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatent_titles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mpatent_titles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'patent_titles' is not defined"
     ]
    }
   ],
   "source": [
    "# function to view the first 10 columns of the titles dataframe\n",
    "def view_data(dataframe, *args):\n",
    "    col_data_list = []\n",
    "    for arg in args:\n",
    "        col_data = dataframe.iloc[0:10, arg]\n",
    "        col_header = dataframe.columns[arg]\n",
    "        col_data_list.append((col_header, col_data))\n",
    "    return col_data_list\n",
    "\n",
    "patent_titles.shape\n",
    "view_data(patent_titles,range(0,7))\n",
    "patent_titles.iloc[0:10,0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dd494b-05a5-4f4d-8399-645dce7d0e06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

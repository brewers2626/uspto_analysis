{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed7cc3a-c858-4878-aa78-3748ebbc822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch\n",
    "# !pip install google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07138255-6220-48e0-bcba-2505a7a0d701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import needed packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "\n",
    "import transformers\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForWholeWordMask\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig, AutoModel\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9507251-925b-4da8-8f04-839ed97d1a55",
   "metadata": {},
   "source": [
    "# Process to read and load data from the GCP bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0432257-f7a0-442d-9878-18438cab02fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from the GCP bucket\n",
    "# data from the kaggle competition website\n",
    "from google.cloud import storage\n",
    "\n",
    "bucket_name = 'cliffm_uspto_kaggle_data'\n",
    "\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "\n",
    "# used when the files are in a subfolder of the bucket\n",
    "'''my_prefix = 'csv/' # name of the subfolder\n",
    "blobs = bucket.list_blobs(delimiter = '/')\n",
    "\n",
    "for blob in blobs:\n",
    "    if(blob.name != my_prefix): # ignore the subfolder itself\n",
    "        file_name = blob.name.replace(my_prefix, \"\")\n",
    "        blob.download_to_filename(file_name) # download the file to the machine\n",
    "        df = pd.read_csv(file_name) # load the data\n",
    "        print(df)\n",
    "'''\n",
    "\n",
    "# use this code for when the files are not in a subfolder; i.e. in the first level of the bucket\n",
    "blobs = bucket.list_blobs()\n",
    "\n",
    "for blob in blobs:\n",
    "    file_name = blob.name\n",
    "    blob.download_to_filename(file_name) # download the file to the machine\n",
    "    df = pd.read_csv(file_name) # load the data\n",
    "    # print(df)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fb256e-23bf-48e8-8f38-fafeac8a22d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "965a20cd-7c08-4f73-a84f-7a3d7137249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data from the folder\n",
    "patent_train = pd.read_csv('/home/jupyter/uspto_analysis/train.csv')\n",
    "patent_test = pd.read_csv('/home/jupyter/uspto_analysis/test.csv')\n",
    "patent_titles = pd.read_csv('/home/jupyter/uspto_analysis/titles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f446080-8f4d-4992-b9fb-ffe1a8de394b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66d6c68f-8ec7-4bd9-8d7e-509482c60d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining of the training dataset\n",
    "patents_combined = patent_train.merge(patent_titles, how = 'left', left_on = 'context', right_on = 'code')\n",
    "patents_combined = patents_combined[['id', 'anchor', 'target', 'context', 'title', 'score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bdfe7cc-2f77-4a5f-a5a1-e448d7299287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining the testing dataset\n",
    "testing_combined = patent_test.merge(patent_titles, how = 'left', left_on = 'context', right_on = 'code')\n",
    "testing_combined = testing_combined[['id', 'anchor', 'target', 'context', 'title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3e34da-366d-4494-9885-f1263b1e8aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5459a50-acf8-419d-813a-27d85d2007ef",
   "metadata": {},
   "source": [
    "## Read in the DeBERTA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c88c7bd7-663b-46ab-b142-eb7d105302bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the DeBERTA model\n",
    "model_name = 'microsoft/deberta-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ec78399-dafe-48e0-85ec-b994448d071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilization of the DeBERTA tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa41cbca-66b0-42e1-b545-a0e7d6a2ba84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57ed136c-5227-4a59-89f6-a798b06505d8",
   "metadata": {},
   "source": [
    "# Text Processing Procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "878370c6-0574-4dff-85f6-501dc3732097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the target and title datafields\n",
    "# include a seperator between the target and title texts\n",
    "\n",
    "patents_combined['input'] = patents_combined['target'] + tokenizer.sep_token + patents_combined['title'].apply(str.lower)\n",
    "testing_combined['input'] = testing_combined['target'] + tokenizer.sep_token + testing_combined['title'].apply(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f4c3ae2-f8fc-47f8-a309-44131da92fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abatement of pollution</td>\n",
       "      <td>A47</td>\n",
       "      <td>FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>abatement of pollution[SEP]furniture; domestic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7b9652b17b68b7a4</td>\n",
       "      <td>abatement</td>\n",
       "      <td>act of abating</td>\n",
       "      <td>A47</td>\n",
       "      <td>FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>act of abating[SEP]furniture; domestic article...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36d72442aefd8232</td>\n",
       "      <td>abatement</td>\n",
       "      <td>active catalyst</td>\n",
       "      <td>A47</td>\n",
       "      <td>FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>active catalyst[SEP]furniture; domestic articl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5296b0c19e1ce60e</td>\n",
       "      <td>abatement</td>\n",
       "      <td>eliminating process</td>\n",
       "      <td>A47</td>\n",
       "      <td>FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>eliminating process[SEP]furniture; domestic ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54c1e3b9184cb5b6</td>\n",
       "      <td>abatement</td>\n",
       "      <td>forest region</td>\n",
       "      <td>A47</td>\n",
       "      <td>FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>forest region[SEP]furniture; domestic articles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36468</th>\n",
       "      <td>8e1386cbefd7f245</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden article</td>\n",
       "      <td>B44</td>\n",
       "      <td>DECORATIVE ARTS</td>\n",
       "      <td>1.00</td>\n",
       "      <td>wooden article[SEP]decorative arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36469</th>\n",
       "      <td>42d9e032d1cd3242</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden box</td>\n",
       "      <td>B44</td>\n",
       "      <td>DECORATIVE ARTS</td>\n",
       "      <td>0.50</td>\n",
       "      <td>wooden box[SEP]decorative arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36470</th>\n",
       "      <td>208654ccb9e14fa3</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden handle</td>\n",
       "      <td>B44</td>\n",
       "      <td>DECORATIVE ARTS</td>\n",
       "      <td>0.50</td>\n",
       "      <td>wooden handle[SEP]decorative arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36471</th>\n",
       "      <td>756ec035e694722b</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden material</td>\n",
       "      <td>B44</td>\n",
       "      <td>DECORATIVE ARTS</td>\n",
       "      <td>0.75</td>\n",
       "      <td>wooden material[SEP]decorative arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36472</th>\n",
       "      <td>8d135da0b55b8c88</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden substrate</td>\n",
       "      <td>B44</td>\n",
       "      <td>DECORATIVE ARTS</td>\n",
       "      <td>0.50</td>\n",
       "      <td>wooden substrate[SEP]decorative arts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36473 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id        anchor                  target context  \\\n",
       "0      37d61fd2272659b1     abatement  abatement of pollution     A47   \n",
       "1      7b9652b17b68b7a4     abatement          act of abating     A47   \n",
       "2      36d72442aefd8232     abatement         active catalyst     A47   \n",
       "3      5296b0c19e1ce60e     abatement     eliminating process     A47   \n",
       "4      54c1e3b9184cb5b6     abatement           forest region     A47   \n",
       "...                 ...           ...                     ...     ...   \n",
       "36468  8e1386cbefd7f245  wood article          wooden article     B44   \n",
       "36469  42d9e032d1cd3242  wood article              wooden box     B44   \n",
       "36470  208654ccb9e14fa3  wood article           wooden handle     B44   \n",
       "36471  756ec035e694722b  wood article         wooden material     B44   \n",
       "36472  8d135da0b55b8c88  wood article        wooden substrate     B44   \n",
       "\n",
       "                                                   title  score  \\\n",
       "0      FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...   0.50   \n",
       "1      FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...   0.75   \n",
       "2      FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...   0.25   \n",
       "3      FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...   0.50   \n",
       "4      FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...   0.00   \n",
       "...                                                  ...    ...   \n",
       "36468                                    DECORATIVE ARTS   1.00   \n",
       "36469                                    DECORATIVE ARTS   0.50   \n",
       "36470                                    DECORATIVE ARTS   0.50   \n",
       "36471                                    DECORATIVE ARTS   0.75   \n",
       "36472                                    DECORATIVE ARTS   0.50   \n",
       "\n",
       "                                                   input  \n",
       "0      abatement of pollution[SEP]furniture; domestic...  \n",
       "1      act of abating[SEP]furniture; domestic article...  \n",
       "2      active catalyst[SEP]furniture; domestic articl...  \n",
       "3      eliminating process[SEP]furniture; domestic ar...  \n",
       "4      forest region[SEP]furniture; domestic articles...  \n",
       "...                                                  ...  \n",
       "36468                 wooden article[SEP]decorative arts  \n",
       "36469                     wooden box[SEP]decorative arts  \n",
       "36470                  wooden handle[SEP]decorative arts  \n",
       "36471                wooden material[SEP]decorative arts  \n",
       "36472               wooden substrate[SEP]decorative arts  \n",
       "\n",
       "[36473 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patents_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28885ee0-a2b1-4fb5-80cd-ed1f604185a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bcc8fa5d-0ea4-4447-ae55-fa9721b02f30",
   "metadata": {},
   "source": [
    "# Setting up the training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16a64346-d366-4517-9de0-a6b6c9f16ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and validation datasets\n",
    "    # 80% of records for training, 20% for testing\n",
    "training_patents, evaluation_patents = train_test_split(patents_combined, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc33a106-3c70-4182-a1ca-68d127b20a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to generate the training dataset\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, patents_combined):\n",
    "        self.input = patents_combined['input'].values.astype(str)\n",
    "        self.anchor = patents_combined['anchor'].values.astype(str)\n",
    "        self.label = patents_combined['score'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = self.input[item]\n",
    "        anchor = self.anchor[item]\n",
    "        label = self.label[item]\n",
    "        model_inputs = tokenizer(inputs, anchor, max_length = 100, padding = 'max_length', truncation = True)\n",
    "        return {**model_inputs, 'label':torch.as_tensor(label, dtype = torch.float)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d567ef3-5692-4533-899e-73d146730e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to generate the validation dataset\n",
    "class EvalDataset(Dataset):\n",
    "    def __init__(self, patents_combined):\n",
    "        self.input = patents_combined['input'].values.astype(str)\n",
    "        self.anchor = patents_combined['anchor'].values.astype(str)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = self.input[item]\n",
    "        anchor = self.anchor[item]\n",
    "        model_inputs = tokenizer(inputs, anchor, max_length = 100, padding = 'max_length', truncation = True)\n",
    "        return {**model_inputs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "205c0bac-8836-414a-b2ac-73d410f580d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate the metrics that will be used to evaluate the model performance\n",
    "# generates the scores between the two text phrases\n",
    "def metrics(eval_predictions):\n",
    "    predictions, labels = eval_predictions\n",
    "    predictions = predictions.reshape(len(predictions))\n",
    "    return {'pearson': np.corrcoef(predictions, labels)[0][1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86150d8-5995-49eb-9f97-97b739ede9de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f290da5-e19f-42f3-ad49-101be44fd46e",
   "metadata": {},
   "source": [
    "# Setup the DeBERTA Model\n",
    "### Defining the hyperparameters and measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bca81ca2-fbc0-4052-9fbd-8fb1eba21b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# define the deberta model that will be used\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "722efb09-0740-40c9-80b5-1055a46102b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the pearson correlation metric to be used for evaluating the model\n",
    "# define the size of the batch - 128\n",
    "# define the epoch evaluation strategy\n",
    "model_metric = 'pearson'\n",
    "batch_size = 128\n",
    "arguments = TrainingArguments('model_test', evaluation_strategy = 'epoch', save_strategy='epoch', learning_rate = 2e-5, per_device_train_batch_size=batch_size,\n",
    "                              per_device_eval_batch_size=batch_size*2, num_train_epochs = 4, weight_decay = 0.01, load_best_model_at_end= True,\n",
    "                              metric_for_best_model= model_metric, save_total_limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cef75ba9-ffbe-4e3b-9288-7041804aefa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the training and validation datasets\n",
    "train_dataset = TrainDataset(training_patents)\n",
    "validation_dataset = TrainDataset(evaluation_patents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c62f0d-3b66-45f3-b191-9843cfb6772c",
   "metadata": {},
   "source": [
    "### Pass in hyperparameters for the model to be trained on the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08830f4c-1b3b-46c3-b093-04a78ab05e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the trainer\n",
    "trainer = Trainer(model, arguments, train_dataset = train_dataset, eval_dataset = validation_dataset,\n",
    "                  tokenizer = tokenizer, compute_metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c197ca1-de20-439d-80cc-fa37185e1e0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3500/839225473.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run the trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "# run the trainer\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072f09cc-a5dd-43b8-bcf3-1223a6475038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71efe65a-44e9-4325-bd42-c7cef0c2f4f8",
   "metadata": {},
   "source": [
    "### setup the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffa7f95-9c99-4379-bf0f-0531970579fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = EvalDataset(testing_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abea4b75-e8b0-4f6a-a7eb-fe638b8fd617",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = trainer.predict(validation_data).predictions.astype(float)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066edc72-65c9-46ba-8506-5fe4e2466c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = np.clip(outputs,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6441266-739d-43aa-a148-72e75b4913a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71c146ac-2901-4722-aa74-0df313859d7f",
   "metadata": {},
   "source": [
    "# Export the predictions to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850e516f-3820-4841-b535-2ac689ef06a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4378116d-257f-4106-9ee4-2e91082fbbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = datasets.Dataset.from_dict({\n",
    "    'id': testing_combined['id'],\n",
    "    'score': outputs.flatten()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545b7dd6-a0bb-4fc8-a4d3-cc777dddf491",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66243735-82dc-497d-9d2b-ab2bd53944de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5071f915-e4a9-4e77-aa43-35b958ec01db",
   "metadata": {},
   "source": [
    "# Patent EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afd940b-7df3-44f5-9b97-f2c1a5bc2f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Description of the data fields ---\n",
    "# patent_train and patent_test\n",
    "    # id - unique identifier for a pair of phrases\n",
    "    # anchor - first phrase\n",
    "    # target - second phrase\n",
    "    # context - CPC classification which indicates the context which the similarity is to be scored\n",
    "    # score - similarity between the two phrases\n",
    "    \n",
    "# patent_titles\n",
    "    # code - hierarchical code used to categorize the patent; corresponds to the context field in patent_train and patent_test dataframe\n",
    "    # title - description of the code field\n",
    "    # section - first symbol in the title field; ranges from A - H and Y\n",
    "    # class - 2 digit class\n",
    "    # subclass - 1 letter code subclass\n",
    "    # group - 1-3 digit group code value\n",
    "    # main_group - 2+ sigit main or subgroup after the / symbol\n",
    "    # EXAMPLE: patent_titles.loc[3,'code'] = 'A01B1/00'\n",
    "        # title = 'Hand tools (edge trimmers for lawns A01G3/06  {; machines for working soil A01B35/00; making hand tools B21D})'\n",
    "        # section = A\n",
    "        # class = 1.0\n",
    "        # subclass = B\n",
    "        # group = 1.0\n",
    "        # main_group = 00\n",
    "        \n",
    "# --- Description of the data fields ---\n",
    "\n",
    "patent_train.head()\n",
    "patent_test.head()\n",
    "patent_titles.head()\n",
    "# patent_cpc.head()\n",
    "\n",
    "patent_train.shape\n",
    "\n",
    "# data fields\n",
    "patent_train.columns\n",
    "patent_titles.columns\n",
    "# patent_cpc.columns\n",
    "\n",
    "# function to view the first 10 columns of the titles dataframe\n",
    "def view_data(dataframe, *args):\n",
    "    col_data_list = []\n",
    "    for arg in args:\n",
    "        col_data = dataframe.iloc[0:10, arg]\n",
    "        col_header = dataframe.columns[arg]\n",
    "        col_data_list.append((col_header, col_data))\n",
    "    return col_data_list\n",
    "\n",
    "patent_titles.shape\n",
    "view_data(patent_titles,range(0,7))\n",
    "patent_titles.iloc[0:10,0:6]\n",
    "\n",
    "# patent_cpc.shape\n",
    "# view_data(patent_cpc,0,1,2,3,4,5,6,7)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

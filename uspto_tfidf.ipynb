{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "189ab5f1-b958-4bc7-ace3-12160eda2394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from collections import Counter\n",
    "import re\n",
    "import time\n",
    "\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# text processing\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cc1e65-f7c3-452d-afc3-ab6dfcfc5754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a5cd2e8-11f9-41e0-bde5-000b28025acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Description of the data fields ---\n",
    "# patent_train and patent_test\n",
    "    # id - unique identifier for a pair of phrases\n",
    "    # anchor - first phrase\n",
    "    # target - second phrase\n",
    "    # context - CPC classification which indicates the context which the similarity is to be scored\n",
    "    # score - similarity between the two phrases\n",
    "    \n",
    "# patent_titles\n",
    "    # code - hierarchical code used to categorize the patent; corresponds to the context field in patent_train and patent_test dataframe\n",
    "    # title - description of the code field\n",
    "    # section - first symbol in the title field; ranges from A - H and Y\n",
    "    # class - 2 digit class\n",
    "    # subclass - 1 letter code subclass\n",
    "    # group - 1-3 digit group code value\n",
    "    # main_group - 2+ sigit main or subgroup after the / symbol\n",
    "    # EXAMPLE: patent_titles.loc[3,'code'] = 'A01B1/00'\n",
    "        # title = 'Hand tools (edge trimmers for lawns A01G3/06  {; machines for working soil A01B35/00; making hand tools B21D})'\n",
    "        # section = A\n",
    "        # class = 1.0\n",
    "        # subclass = B\n",
    "        # group = 1.0\n",
    "        # main_group = 00\n",
    "        \n",
    "# --- Description of the data fields ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f252aef-78c6-4394-bb4a-fb2341ad33f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fcb65ec-59aa-4e61-8403-a6b9e8190cc3",
   "metadata": {},
   "source": [
    "# Preprocessing of the patents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4420cc7e-c58e-4aa6-bd23-4d7567ecacd9",
   "metadata": {},
   "source": [
    "### Read in the data that has been uploaded to the GCP bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bdfc732-5048-4ec0-8369-903257eaa837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data from the folder\n",
    "patent_train = pd.read_csv('/home/jupyter/uspto_analysis/train.csv')\n",
    "patent_test = pd.read_csv('/home/jupyter/uspto_analysis/test.csv')\n",
    "patent_titles = pd.read_csv('/home/jupyter/uspto_analysis/titles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c0b74f-f114-4c68-bee6-94687042ebb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0f6c25e-9a5f-4bad-a556-9cb805f5f834",
   "metadata": {},
   "source": [
    "### Join the training and testing datasets with the titles csv\n",
    "titles.csv contains more information on the context of the patent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96572b99-5c22-4a3d-adbc-5feccc9c7015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining the training dataset\n",
    "patents_combined = patent_train.merge(patent_titles, how = 'left', left_on = 'context', right_on = 'code')\n",
    "patents_combined = patents_combined[['id', 'anchor', 'target', 'context', 'title', 'score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d30b7ddd-c956-412b-a634-2b8b5f9d5449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining the testing dataset\n",
    "testing_combined = patent_test.merge(patent_titles, how = 'left', left_on = 'context', right_on = 'code')\n",
    "testing_combined = testing_combined[['id', 'anchor', 'target', 'context', 'title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23530c25-849a-4dc2-a4af-c86dfa843647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['anchor', 'target', 'context', 'title', 'score'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a copy of the original dataframe and set the id as the index\n",
    "text_processing_frame = patents_combined.copy()\n",
    "text_processing_frame = text_processing_frame.set_index('id')\n",
    "text_processing_frame.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0abdd83-a447-42ea-b417-d801b5c147ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c9a39e7-6843-4d73-9156-77ab63923354",
   "metadata": {},
   "source": [
    "## Processing the text of the patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5576df13-0f79-45cd-9a54-35a788cc5f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all of the text fields to lowercase \n",
    "    # anchor, target, and code\n",
    "text_processing_frame['anchor'] = text_processing_frame['anchor'].str.lower()\n",
    "text_processing_frame['target'] = text_processing_frame['target'].str.lower()\n",
    "text_processing_frame['title'] = text_processing_frame['title'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a42d9084-34f6-447e-af1d-cd46fea230d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# remove all non-alphabetic characters from the anchor, target, and title fields\n",
    "text_processing_frame['anchor'] = text_processing_frame.anchor.str.replace('\\W+', ' ')\n",
    "text_processing_frame['target'] = text_processing_frame.target.str.replace('\\W+', ' ')\n",
    "text_processing_frame['title_alpha'] = text_processing_frame.title.str.replace('\\W+', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4165d8e-e6a5-451f-97ca-559f63877a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization of the data fields\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0a36651-6cbc-43be-922a-1a1fe9d1ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the lemmatization function to the text datafields\n",
    "text_processing_frame['lemmatized_anchor'] = text_processing_frame.anchor.apply(lemmatize_text)\n",
    "text_processing_frame['lemmatized_target'] = text_processing_frame.target.apply(lemmatize_text)\n",
    "text_processing_frame['lemmatized_title'] = text_processing_frame.title_alpha.apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09aa82d5-b054-4acc-8b8a-30aa02dcc395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new dataframe with the the needed datafields\n",
    "patent_select = pd.DataFrame(text_processing_frame[['lemmatized_anchor','lemmatized_target','lemmatized_title', 'context', 'score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2b24445-1ab5-4542-b75d-6373d866e214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmatized_anchor</th>\n",
       "      <th>lemmatized_target</th>\n",
       "      <th>lemmatized_title</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37d61fd2272659b1</th>\n",
       "      <td>[abatement]</td>\n",
       "      <td>[abatement, of, pollution]</td>\n",
       "      <td>[furniture, domestic, article, or, appliance, ...</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7b9652b17b68b7a4</th>\n",
       "      <td>[abatement]</td>\n",
       "      <td>[act, of, abating]</td>\n",
       "      <td>[furniture, domestic, article, or, appliance, ...</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36d72442aefd8232</th>\n",
       "      <td>[abatement]</td>\n",
       "      <td>[active, catalyst]</td>\n",
       "      <td>[furniture, domestic, article, or, appliance, ...</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5296b0c19e1ce60e</th>\n",
       "      <td>[abatement]</td>\n",
       "      <td>[eliminating, process]</td>\n",
       "      <td>[furniture, domestic, article, or, appliance, ...</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54c1e3b9184cb5b6</th>\n",
       "      <td>[abatement]</td>\n",
       "      <td>[forest, region]</td>\n",
       "      <td>[furniture, domestic, article, or, appliance, ...</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8e1386cbefd7f245</th>\n",
       "      <td>[wood, article]</td>\n",
       "      <td>[wooden, article]</td>\n",
       "      <td>[decorative, art]</td>\n",
       "      <td>B44</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42d9e032d1cd3242</th>\n",
       "      <td>[wood, article]</td>\n",
       "      <td>[wooden, box]</td>\n",
       "      <td>[decorative, art]</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208654ccb9e14fa3</th>\n",
       "      <td>[wood, article]</td>\n",
       "      <td>[wooden, handle]</td>\n",
       "      <td>[decorative, art]</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756ec035e694722b</th>\n",
       "      <td>[wood, article]</td>\n",
       "      <td>[wooden, material]</td>\n",
       "      <td>[decorative, art]</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8d135da0b55b8c88</th>\n",
       "      <td>[wood, article]</td>\n",
       "      <td>[wooden, substrate]</td>\n",
       "      <td>[decorative, art]</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36473 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 lemmatized_anchor           lemmatized_target  \\\n",
       "id                                                               \n",
       "37d61fd2272659b1       [abatement]  [abatement, of, pollution]   \n",
       "7b9652b17b68b7a4       [abatement]          [act, of, abating]   \n",
       "36d72442aefd8232       [abatement]          [active, catalyst]   \n",
       "5296b0c19e1ce60e       [abatement]      [eliminating, process]   \n",
       "54c1e3b9184cb5b6       [abatement]            [forest, region]   \n",
       "...                            ...                         ...   \n",
       "8e1386cbefd7f245   [wood, article]           [wooden, article]   \n",
       "42d9e032d1cd3242   [wood, article]               [wooden, box]   \n",
       "208654ccb9e14fa3   [wood, article]            [wooden, handle]   \n",
       "756ec035e694722b   [wood, article]          [wooden, material]   \n",
       "8d135da0b55b8c88   [wood, article]         [wooden, substrate]   \n",
       "\n",
       "                                                   lemmatized_title context  \\\n",
       "id                                                                            \n",
       "37d61fd2272659b1  [furniture, domestic, article, or, appliance, ...     A47   \n",
       "7b9652b17b68b7a4  [furniture, domestic, article, or, appliance, ...     A47   \n",
       "36d72442aefd8232  [furniture, domestic, article, or, appliance, ...     A47   \n",
       "5296b0c19e1ce60e  [furniture, domestic, article, or, appliance, ...     A47   \n",
       "54c1e3b9184cb5b6  [furniture, domestic, article, or, appliance, ...     A47   \n",
       "...                                                             ...     ...   \n",
       "8e1386cbefd7f245                                  [decorative, art]     B44   \n",
       "42d9e032d1cd3242                                  [decorative, art]     B44   \n",
       "208654ccb9e14fa3                                  [decorative, art]     B44   \n",
       "756ec035e694722b                                  [decorative, art]     B44   \n",
       "8d135da0b55b8c88                                  [decorative, art]     B44   \n",
       "\n",
       "                  score  \n",
       "id                       \n",
       "37d61fd2272659b1   0.50  \n",
       "7b9652b17b68b7a4   0.75  \n",
       "36d72442aefd8232   0.25  \n",
       "5296b0c19e1ce60e   0.50  \n",
       "54c1e3b9184cb5b6   0.00  \n",
       "...                 ...  \n",
       "8e1386cbefd7f245   1.00  \n",
       "42d9e032d1cd3242   0.50  \n",
       "208654ccb9e14fa3   0.50  \n",
       "756ec035e694722b   0.75  \n",
       "8d135da0b55b8c88   0.50  \n",
       "\n",
       "[36473 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patent_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89065d5-d400-4d20-a662-2d53862f5b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d829fdf-6a0e-48e9-9d93-a3b5896c33a5",
   "metadata": {},
   "source": [
    "### Process to create a word dictionary for further filtering out tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1b00811-ff1c-4884-8078-f65df05739f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of all tokens - lemmatized versions\n",
    "anchor_list = list(text_processing_frame['lemmatized_anchor'])\n",
    "target_list = list(text_processing_frame['lemmatized_target'])\n",
    "title_list = list(text_processing_frame['lemmatized_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d08280f-4e08-491c-9509-b367436baa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_list = (anchor_list + target_list + title_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "129fee96-9d71-4ba0-8529-f38f27d3b684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of tokens = 386,751\n",
    "# number of unique tokens\n",
    "    # lemmatization = 8,031\n",
    "all_words = []\n",
    "for item in combined_list:\n",
    "    for word in item:\n",
    "        all_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a45f108c-3fe2-44ba-b7bd-849bb6ae24cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386751"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc72ec86-049c-4592-8492-0e5492f25e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency of each individual token\n",
    "# convert to a dictionary\n",
    "token_count = FreqDist(all_words)\n",
    "len(token_count)\n",
    "token_list = list(token_count)\n",
    "token_count_dict = dict(token_count)\n",
    "\n",
    "sorted_dict = sorted(token_count_dict.items(), key = lambda x: x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62754af3-fcad-4a97-a4db-6acea5a19d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8031"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba3c7dd8-5843-4f8f-8e75-058f9a2d4f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of tokens that are to be removed\n",
    "stop_words = list(stopwords.words('english'))\n",
    "token_len_one = [w for w in token_list if len(w) == 1]\n",
    "token_len_two = [w for w in token_list if len(w) == 2]\n",
    "numeric_tokens = [num for num in token_list if any(c.isdigit() for c in num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "594c6218-2f21-4a48-b3f9-a0fb6c973838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_len_two"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fda0fd-0d37-4dbb-9f14-c075b8e8569f",
   "metadata": {},
   "source": [
    "### EDA - Token Descriptions\n",
    "- lengths for each unique token\n",
    "- avg, max, min, sd of tokens\n",
    "- number of consonants in each token\n",
    "- percentiles of token lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9790583-6b49-4b90-a318-fd583857cca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of lengths for each of the tokens\n",
    "token_length_list = []\n",
    "for word in token_list:\n",
    "    token_len = len(word)\n",
    "    token_length_list.append(token_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28a41a06-2f9b-48ef-8aac-9a38cd443fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9313652766188376"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average length of tokens\n",
    "# max length of tokens\n",
    "# standard deviation of tokens\n",
    "avg_token = sum(map(len, token_list))/len(token_list)\n",
    "avg_token\n",
    "max_length = max(token_length_list)\n",
    "max_length\n",
    "token_sd = np.std(token_length_list)\n",
    "token_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25ce9ba1-a1a7-4e15-b5ce-728ab3eae0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of consonants in tokens\n",
    "vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "token_data = []\n",
    "for token in token_list:\n",
    "    token_len = len(token)\n",
    "    consonants = 0\n",
    "    for letter in token:\n",
    "        if letter not in vowels:\n",
    "            consonants = consonants + 1\n",
    "    token_data.append((token, token_len, consonants))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4964b146-1bcd-46ab-b6a6-84a494426b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with metadata about each of the unique tokens\n",
    "token_count_df = pd.DataFrame(token_count_dict.items(), columns = ['token', 'token_count'])\n",
    "token_metadata = pd.DataFrame(token_data, columns = ['token', 'token_length', 'consonant_count'])\n",
    "token_metadata = token_metadata.merge(token_count_df, left_on = 'token', right_on = 'token')\n",
    "token_metadata['consonant_percentage'] = token_metadata['consonant_count']/token_metadata['token_length']\n",
    "\n",
    "high_consonants = token_metadata[token_metadata['consonant_percentage'] > 0.9]\n",
    "consonant_list = list(high_consonants['token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b705633c-956e-4d29-9ad0-34df44aca877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for any tokens containing numeric values\n",
    "numeric_tokens = [num for num in token_list if any(c.isdigit() for c in num)]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "051b6f1f-375c-4854-a592-21c58f3fcc27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentiles of token lengths\n",
    "twentyfive_percentile = np.percentile(token_length_list, 25)\n",
    "fifty_percentile = np.percentile(token_length_list, 50)\n",
    "sevenfive_percentile = np.percentile(token_length_list, 75)\n",
    "twentyfive_percentile\n",
    "fifty_percentile\n",
    "sevenfive_percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ec199c2-f951-4078-8c6b-48a6c96553bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playing around with mean and standard deviation of the token lengths\n",
    "# Testing if long tokens should be removed - NO\n",
    "    # Many important long tokens\n",
    "max_length = max(token_length_list)\n",
    "dictionary_lengths = dict(zip(token_list, token_length_list))\n",
    "\n",
    "sd_value = avg_token + (token_sd *2)\n",
    "sd_value_three = avg_token + (token_sd *3)\n",
    "sd_min = avg_token - (token_sd*2)\n",
    "two_sd = [k for k,v in dictionary_lengths.items() if v >= sd_value]\n",
    "three_sd = [k for k,v in dictionary_lengths.items() if v >= sd_value_three]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac69f01-163b-432b-ac06-ad3668e67d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ee766de-0797-4748-84c1-f698548ba61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of tokens to be removed\n",
    "remove_list = stop_words + token_len_one + consonant_list + numeric_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad7205eb-c4d8-4858-89c9-e967c07e821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_anchor = patent_select['lemmatized_anchor']\n",
    "lemmatized_target = patent_select['lemmatized_target']\n",
    "lemmatized_title = patent_select['lemmatized_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1efae59b-524d-4b51-a877-3d9d9e7acaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion to apply the word dictionary to the anchor, target, and title data fields\n",
    "def word_dictionary_apply(patent_datafield):\n",
    "    filter_list = []\n",
    "    for elements in patent_datafield:\n",
    "        inner_filter = []\n",
    "        for token in elements:\n",
    "            if token not in remove_list:\n",
    "                inner_filter.append(token)\n",
    "        filter_list.append(inner_filter)\n",
    "    return filter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f839b78-1fbe-41a7-bac0-e981272885c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the word dictionary to the specified text fields\n",
    "anchor_filter = word_dictionary_apply(lemmatized_anchor)\n",
    "target_filter = word_dictionary_apply(lemmatized_target)\n",
    "title_filter = word_dictionary_apply(lemmatized_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "53688734-3f99-44d4-bcad-c7cb7fff32ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append the text lists to the patent dataframe after the word dictionary has been applied\n",
    "patent_select['anchor_dict'] = anchor_filter\n",
    "patent_select['target_dict'] = target_filter\n",
    "patent_select['title_dict'] = title_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a64227f-0136-4dc3-af04-ef63a34bd1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# future modelling needs input as combined string instead of tokenized text\n",
    "# function to combine the tokenized text fields into a non-tokenized version\n",
    "# add each as a datafield in the dataframe\n",
    "def list_to_string(datafield_list):\n",
    "    string_list = []\n",
    "    for phrase in datafield_list:\n",
    "        new_string = ' '.join(phrase)\n",
    "        string_list.append(new_string)\n",
    "    return string_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5097e783-f66c-4348-88ea-9931465c2840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function to the tokenized text lists\n",
    "anchor_list = list_to_string(anchor_filter)\n",
    "target_list = list_to_string(target_filter)\n",
    "title_list = list_to_string(title_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59500372-1091-4a68-bcdd-a94eb46d853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append back to the dataframe\n",
    "patent_select['anchor_list'] = anchor_list\n",
    "patent_select['target_list'] = target_list\n",
    "patent_select['title_list'] = title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e46ed460-1377-478f-b065-0a821882f47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_select = patent_select.drop(columns = ['lemmatized_anchor','lemmatized_target','lemmatized_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1f5f272-b2a0-40fe-a0f9-3078c6ee3ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new datafield - 'target_title_combined'\n",
    "# concatenate the target and title datafields in order to calculate cosine similarity later on\n",
    "patent_select['target_title_combined'] = patent_select['target_list'] + ' ' + patent_select['title_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37fbcbf7-dc4e-4fce-a2bd-a44b220b9008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "37d61fd2272659b1    abatement pollution furniture domestic article...\n",
       "7b9652b17b68b7a4    act abating furniture domestic article applian...\n",
       "36d72442aefd8232    active catalyst furniture domestic article app...\n",
       "5296b0c19e1ce60e    eliminating process furniture domestic article...\n",
       "54c1e3b9184cb5b6    forest region furniture domestic article appli...\n",
       "                                          ...                        \n",
       "8e1386cbefd7f245                        wooden article decorative art\n",
       "42d9e032d1cd3242                            wooden box decorative art\n",
       "208654ccb9e14fa3                         wooden handle decorative art\n",
       "756ec035e694722b                       wooden material decorative art\n",
       "8d135da0b55b8c88                      wooden substrate decorative art\n",
       "Name: target_title_combined, Length: 36473, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patent_select['target_title_combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d5347e-2183-42f9-9778-044c977388ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf751bac-aefd-48d5-b1c9-24701ef897f8",
   "metadata": {},
   "source": [
    "## Process for tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "400fdc7d-9754-4104-8b9b-24003b64371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_list = list(patent_select['anchor_list'])\n",
    "target_list = list(patent_select['target_list'])\n",
    "title_list = list(patent_select['title_list'])\n",
    "target_title_combined = list(patent_select['target_title_combined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b75f85b1-415c-4fd1-b6ab-fa43c3607491",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_tokenize = []\n",
    "target_tokenize = []\n",
    "title_tokenize = []\n",
    "target_title_tokenize = []\n",
    "for item in anchor_list:\n",
    "    anchor_token = word_tokenize(item)\n",
    "    anchor_tokenize.append(anchor_token)\n",
    "for item in target_list:\n",
    "    target_token = word_tokenize(item)\n",
    "    target_tokenize.append(target_token)\n",
    "for item in title_list:\n",
    "    title_token = word_tokenize(item)\n",
    "    title_tokenize.append(title_tokenize)\n",
    "for item in target_title_combined:\n",
    "    target_title_token = word_tokenize(item)\n",
    "    target_title_tokenize.append(target_title_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cda45b31-b37a-4e3d-a4c7-4cc7f6aaa302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"patent_select['anchor_tokenize'] = anchor_tokenize\\npatent_select['target_tokenize'] = target_tokenize\\npatent_select['title_tokenize'] = title_tokenize\\npatent_select['target_title_tokenize'] = target_title_tokenize\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''patent_select['anchor_tokenize'] = anchor_tokenize\n",
    "patent_select['target_tokenize'] = target_tokenize\n",
    "patent_select['title_tokenize'] = title_tokenize\n",
    "patent_select['target_title_tokenize'] = target_title_tokenize'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c1450a8d-8ac4-4925-9317-bb0ce388a16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>anchor_dict</th>\n",
       "      <th>target_dict</th>\n",
       "      <th>title_dict</th>\n",
       "      <th>anchor_list</th>\n",
       "      <th>target_list</th>\n",
       "      <th>title_list</th>\n",
       "      <th>target_title_combined</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37d61fd2272659b1</th>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>[abatement]</td>\n",
       "      <td>[abatement, pollution]</td>\n",
       "      <td>[furniture, domestic, article, appliance, coff...</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abatement pollution</td>\n",
       "      <td>furniture domestic article appliance coffee mi...</td>\n",
       "      <td>abatement pollution furniture domestic article...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7b9652b17b68b7a4</th>\n",
       "      <td>A47</td>\n",
       "      <td>0.75</td>\n",
       "      <td>[abatement]</td>\n",
       "      <td>[act, abating]</td>\n",
       "      <td>[furniture, domestic, article, appliance, coff...</td>\n",
       "      <td>abatement</td>\n",
       "      <td>act abating</td>\n",
       "      <td>furniture domestic article appliance coffee mi...</td>\n",
       "      <td>act abating furniture domestic article applian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36d72442aefd8232</th>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "      <td>[abatement]</td>\n",
       "      <td>[active, catalyst]</td>\n",
       "      <td>[furniture, domestic, article, appliance, coff...</td>\n",
       "      <td>abatement</td>\n",
       "      <td>active catalyst</td>\n",
       "      <td>furniture domestic article appliance coffee mi...</td>\n",
       "      <td>active catalyst furniture domestic article app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5296b0c19e1ce60e</th>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>[abatement]</td>\n",
       "      <td>[eliminating, process]</td>\n",
       "      <td>[furniture, domestic, article, appliance, coff...</td>\n",
       "      <td>abatement</td>\n",
       "      <td>eliminating process</td>\n",
       "      <td>furniture domestic article appliance coffee mi...</td>\n",
       "      <td>eliminating process furniture domestic article...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54c1e3b9184cb5b6</th>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[abatement]</td>\n",
       "      <td>[forest, region]</td>\n",
       "      <td>[furniture, domestic, article, appliance, coff...</td>\n",
       "      <td>abatement</td>\n",
       "      <td>forest region</td>\n",
       "      <td>furniture domestic article appliance coffee mi...</td>\n",
       "      <td>forest region furniture domestic article appli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8e1386cbefd7f245</th>\n",
       "      <td>B44</td>\n",
       "      <td>1.00</td>\n",
       "      <td>[wood, article]</td>\n",
       "      <td>[wooden, article]</td>\n",
       "      <td>[decorative, art]</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden article</td>\n",
       "      <td>decorative art</td>\n",
       "      <td>wooden article decorative art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42d9e032d1cd3242</th>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "      <td>[wood, article]</td>\n",
       "      <td>[wooden, box]</td>\n",
       "      <td>[decorative, art]</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden box</td>\n",
       "      <td>decorative art</td>\n",
       "      <td>wooden box decorative art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208654ccb9e14fa3</th>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "      <td>[wood, article]</td>\n",
       "      <td>[wooden, handle]</td>\n",
       "      <td>[decorative, art]</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden handle</td>\n",
       "      <td>decorative art</td>\n",
       "      <td>wooden handle decorative art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756ec035e694722b</th>\n",
       "      <td>B44</td>\n",
       "      <td>0.75</td>\n",
       "      <td>[wood, article]</td>\n",
       "      <td>[wooden, material]</td>\n",
       "      <td>[decorative, art]</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden material</td>\n",
       "      <td>decorative art</td>\n",
       "      <td>wooden material decorative art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8d135da0b55b8c88</th>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "      <td>[wood, article]</td>\n",
       "      <td>[wooden, substrate]</td>\n",
       "      <td>[decorative, art]</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden substrate</td>\n",
       "      <td>decorative art</td>\n",
       "      <td>wooden substrate decorative art</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36473 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 context  score      anchor_dict             target_dict  \\\n",
       "id                                                                         \n",
       "37d61fd2272659b1     A47   0.50      [abatement]  [abatement, pollution]   \n",
       "7b9652b17b68b7a4     A47   0.75      [abatement]          [act, abating]   \n",
       "36d72442aefd8232     A47   0.25      [abatement]      [active, catalyst]   \n",
       "5296b0c19e1ce60e     A47   0.50      [abatement]  [eliminating, process]   \n",
       "54c1e3b9184cb5b6     A47   0.00      [abatement]        [forest, region]   \n",
       "...                  ...    ...              ...                     ...   \n",
       "8e1386cbefd7f245     B44   1.00  [wood, article]       [wooden, article]   \n",
       "42d9e032d1cd3242     B44   0.50  [wood, article]           [wooden, box]   \n",
       "208654ccb9e14fa3     B44   0.50  [wood, article]        [wooden, handle]   \n",
       "756ec035e694722b     B44   0.75  [wood, article]      [wooden, material]   \n",
       "8d135da0b55b8c88     B44   0.50  [wood, article]     [wooden, substrate]   \n",
       "\n",
       "                                                         title_dict  \\\n",
       "id                                                                    \n",
       "37d61fd2272659b1  [furniture, domestic, article, appliance, coff...   \n",
       "7b9652b17b68b7a4  [furniture, domestic, article, appliance, coff...   \n",
       "36d72442aefd8232  [furniture, domestic, article, appliance, coff...   \n",
       "5296b0c19e1ce60e  [furniture, domestic, article, appliance, coff...   \n",
       "54c1e3b9184cb5b6  [furniture, domestic, article, appliance, coff...   \n",
       "...                                                             ...   \n",
       "8e1386cbefd7f245                                  [decorative, art]   \n",
       "42d9e032d1cd3242                                  [decorative, art]   \n",
       "208654ccb9e14fa3                                  [decorative, art]   \n",
       "756ec035e694722b                                  [decorative, art]   \n",
       "8d135da0b55b8c88                                  [decorative, art]   \n",
       "\n",
       "                   anchor_list          target_list  \\\n",
       "id                                                    \n",
       "37d61fd2272659b1     abatement  abatement pollution   \n",
       "7b9652b17b68b7a4     abatement          act abating   \n",
       "36d72442aefd8232     abatement      active catalyst   \n",
       "5296b0c19e1ce60e     abatement  eliminating process   \n",
       "54c1e3b9184cb5b6     abatement        forest region   \n",
       "...                        ...                  ...   \n",
       "8e1386cbefd7f245  wood article       wooden article   \n",
       "42d9e032d1cd3242  wood article           wooden box   \n",
       "208654ccb9e14fa3  wood article        wooden handle   \n",
       "756ec035e694722b  wood article      wooden material   \n",
       "8d135da0b55b8c88  wood article     wooden substrate   \n",
       "\n",
       "                                                         title_list  \\\n",
       "id                                                                    \n",
       "37d61fd2272659b1  furniture domestic article appliance coffee mi...   \n",
       "7b9652b17b68b7a4  furniture domestic article appliance coffee mi...   \n",
       "36d72442aefd8232  furniture domestic article appliance coffee mi...   \n",
       "5296b0c19e1ce60e  furniture domestic article appliance coffee mi...   \n",
       "54c1e3b9184cb5b6  furniture domestic article appliance coffee mi...   \n",
       "...                                                             ...   \n",
       "8e1386cbefd7f245                                     decorative art   \n",
       "42d9e032d1cd3242                                     decorative art   \n",
       "208654ccb9e14fa3                                     decorative art   \n",
       "756ec035e694722b                                     decorative art   \n",
       "8d135da0b55b8c88                                     decorative art   \n",
       "\n",
       "                                              target_title_combined  \n",
       "id                                                                   \n",
       "37d61fd2272659b1  abatement pollution furniture domestic article...  \n",
       "7b9652b17b68b7a4  act abating furniture domestic article applian...  \n",
       "36d72442aefd8232  active catalyst furniture domestic article app...  \n",
       "5296b0c19e1ce60e  eliminating process furniture domestic article...  \n",
       "54c1e3b9184cb5b6  forest region furniture domestic article appli...  \n",
       "...                                                             ...  \n",
       "8e1386cbefd7f245                      wooden article decorative art  \n",
       "42d9e032d1cd3242                          wooden box decorative art  \n",
       "208654ccb9e14fa3                       wooden handle decorative art  \n",
       "756ec035e694722b                     wooden material decorative art  \n",
       "8d135da0b55b8c88                    wooden substrate decorative art  \n",
       "\n",
       "[36473 rows x 9 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patent_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ccb8bdf-a037-45a6-8873-c9f20abe6cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abatement']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_tokenize[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9829719f-c7df-425f-bdb6-fa18a4ec146a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbaed91f-f9bb-462e-abf7-edcb1b4772e1",
   "metadata": {},
   "source": [
    "# Implementation of the Gensim tfidf module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11d3ff4f-8af4-4f9a-a68f-efaa24f01ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patents = anchor_list + target_title_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7fa66d59-65db-41fe-91d0-cf509e746ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the gensim simple_preprocess function to get the text in the correct format for future modelling\n",
    "all_patent_process = [simple_preprocess(item) for item in all_patents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "20e5ddea-083a-45da-9c5a-bd022e5bd6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of all the unique tokens\n",
    "dictionary = corpora.Dictionary(all_patent_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "747cfbbc-23e2-46c8-8625-dbe663444eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the anchor and target/title fields based on the defined dictionary of tokens\n",
    "corpus = [dictionary.doc2bow(text) for text in all_patent_process]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d552faec-275a-47f1-b80c-e98ebf8e3cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abnormal', 'position']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_patent_process[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1eb931a7-8f99-449c-9b1d-2083c7ba426e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (2, 1)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d4e2dc2-fd6a-48f2-8752-2797001a6c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the gensim tfidf model on the corpus\n",
    "tfidf = models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0ebbc7f7-9618-4ae6-b7a2-fb61f1d2a833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a tfidf transformation to the entire corpus of documents\n",
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc06408-4deb-4173-baec-713d24c75603",
   "metadata": {},
   "source": [
    "## Compute a tfidf matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b4d75e60-9f9e-4361-b135-bc376f505f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [dictionary[i] for i in range(len(dictionary))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c1fb7200-5cc9-4b1c-8a7b-d24abdb0c79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = list(range(len(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "10e7b036-987c-4b34-9471-b33e2bcc14ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = pd.DataFrame(np.zeros((len(corpus), len(vocab)), dtype = np.float16), index = index, columns = vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "62b9a082-2969-43a0-a98b-85eb336b3a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in index:\n",
    "    for id_val, freq in tfidf[corpus[idx]]:\n",
    "        tfidf_matrix[dictionary[id_val]][idx] = freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fedcf54d-0e3d-4299-9229-54808a9a4fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_matrix.to_csv('/home/jupyter/uspto_analysis/tfidf_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df2f72c7-813a-416f-9b9e-7868e988fe60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abatement</th>\n",
       "      <th>abnormal</th>\n",
       "      <th>position</th>\n",
       "      <th>absorbent</th>\n",
       "      <th>property</th>\n",
       "      <th>acan</th>\n",
       "      <th>accept</th>\n",
       "      <th>information</th>\n",
       "      <th>achieve</th>\n",
       "      <th>authentication</th>\n",
       "      <th>...</th>\n",
       "      <th>beamsplitter</th>\n",
       "      <th>union</th>\n",
       "      <th>influent</th>\n",
       "      <th>elevating</th>\n",
       "      <th>universal</th>\n",
       "      <th>chase</th>\n",
       "      <th>fixedly</th>\n",
       "      <th>creosote</th>\n",
       "      <th>bat</th>\n",
       "      <th>lumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72941</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72942</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72943</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72944</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72945</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72946 rows × 7694 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       abatement  abnormal  position  absorbent  property  acan  accept  \\\n",
       "0            1.0       0.0       0.0        0.0       0.0   0.0     0.0   \n",
       "1            1.0       0.0       0.0        0.0       0.0   0.0     0.0   \n",
       "2            1.0       0.0       0.0        0.0       0.0   0.0     0.0   \n",
       "3            1.0       0.0       0.0        0.0       0.0   0.0     0.0   \n",
       "4            1.0       0.0       0.0        0.0       0.0   0.0     0.0   \n",
       "...          ...       ...       ...        ...       ...   ...     ...   \n",
       "72941        0.0       0.0       0.0        0.0       0.0   0.0     0.0   \n",
       "72942        0.0       0.0       0.0        0.0       0.0   0.0     0.0   \n",
       "72943        0.0       0.0       0.0        0.0       0.0   0.0     0.0   \n",
       "72944        0.0       0.0       0.0        0.0       0.0   0.0     0.0   \n",
       "72945        0.0       0.0       0.0        0.0       0.0   0.0     0.0   \n",
       "\n",
       "       information  achieve  authentication  ...  beamsplitter  union  \\\n",
       "0              0.0      0.0             0.0  ...           0.0    0.0   \n",
       "1              0.0      0.0             0.0  ...           0.0    0.0   \n",
       "2              0.0      0.0             0.0  ...           0.0    0.0   \n",
       "3              0.0      0.0             0.0  ...           0.0    0.0   \n",
       "4              0.0      0.0             0.0  ...           0.0    0.0   \n",
       "...            ...      ...             ...  ...           ...    ...   \n",
       "72941          0.0      0.0             0.0  ...           0.0    0.0   \n",
       "72942          0.0      0.0             0.0  ...           0.0    0.0   \n",
       "72943          0.0      0.0             0.0  ...           0.0    0.0   \n",
       "72944          0.0      0.0             0.0  ...           0.0    0.0   \n",
       "72945          0.0      0.0             0.0  ...           0.0    0.0   \n",
       "\n",
       "       influent  elevating  universal  chase  fixedly  creosote  bat  lumber  \n",
       "0           0.0        0.0        0.0    0.0      0.0       0.0  0.0     0.0  \n",
       "1           0.0        0.0        0.0    0.0      0.0       0.0  0.0     0.0  \n",
       "2           0.0        0.0        0.0    0.0      0.0       0.0  0.0     0.0  \n",
       "3           0.0        0.0        0.0    0.0      0.0       0.0  0.0     0.0  \n",
       "4           0.0        0.0        0.0    0.0      0.0       0.0  0.0     0.0  \n",
       "...         ...        ...        ...    ...      ...       ...  ...     ...  \n",
       "72941       0.0        0.0        0.0    0.0      0.0       0.0  0.0     0.0  \n",
       "72942       0.0        0.0        0.0    0.0      0.0       0.0  0.0     0.0  \n",
       "72943       0.0        0.0        0.0    0.0      0.0       0.0  0.0     0.0  \n",
       "72944       0.0        0.0        0.0    0.0      0.0       0.0  0.0     0.0  \n",
       "72945       0.0        0.0        0.0    0.0      0.0       0.0  0.0     0.0  \n",
       "\n",
       "[72946 rows x 7694 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4040b7a1-f1e6-4be5-98de-71f17b46e552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6285e243-cba5-47e6-8bb7-c5372e380d72",
   "metadata": {},
   "source": [
    "## Test the tfidf matrix on a few sample patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ae86828c-208b-4d16-a225-da37de4aa8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_tfidf = tfidf_matrix.iloc[0:36473,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c326fa69-52e1-4c78-b9ee-d4564404f9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_tfidf = tfidf_matrix.iloc[36473:,:]\n",
    "combined_tfidf = combined_tfidf.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "97379e24-0295-4961-9c2b-fdc93325b170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abatement</th>\n",
       "      <th>abnormal</th>\n",
       "      <th>position</th>\n",
       "      <th>absorbent</th>\n",
       "      <th>property</th>\n",
       "      <th>acan</th>\n",
       "      <th>accept</th>\n",
       "      <th>information</th>\n",
       "      <th>achieve</th>\n",
       "      <th>authentication</th>\n",
       "      <th>...</th>\n",
       "      <th>beamsplitter</th>\n",
       "      <th>union</th>\n",
       "      <th>influent</th>\n",
       "      <th>elevating</th>\n",
       "      <th>universal</th>\n",
       "      <th>chase</th>\n",
       "      <th>fixedly</th>\n",
       "      <th>creosote</th>\n",
       "      <th>bat</th>\n",
       "      <th>lumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.337158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36468</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36469</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36470</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36471</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36472</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36473 rows × 7694 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       abatement  abnormal  position  absorbent  property  acan  accept  \\\n",
       "0       0.337158       0.0       0.0        0.0       0.0   0.0     0.0   \n",
       "1       0.000000       0.0       0.0        0.0       0.0   0.0     0.0   \n",
       "2       0.000000       0.0       0.0        0.0       0.0   0.0     0.0   \n",
       "3       0.000000       0.0       0.0        0.0       0.0   0.0     0.0   \n",
       "4       0.000000       0.0       0.0        0.0       0.0   0.0     0.0   \n",
       "...          ...       ...       ...        ...       ...   ...     ...   \n",
       "36468   0.000000       0.0       0.0        0.0       0.0   0.0     0.0   \n",
       "36469   0.000000       0.0       0.0        0.0       0.0   0.0     0.0   \n",
       "36470   0.000000       0.0       0.0        0.0       0.0   0.0     0.0   \n",
       "36471   0.000000       0.0       0.0        0.0       0.0   0.0     0.0   \n",
       "36472   0.000000       0.0       0.0        0.0       0.0   0.0     0.0   \n",
       "\n",
       "       information  achieve  authentication  ...  beamsplitter  union  \\\n",
       "0              0.0      0.0             0.0  ...           0.0    0.0   \n",
       "1              0.0      0.0             0.0  ...           0.0    0.0   \n",
       "2              0.0      0.0             0.0  ...           0.0    0.0   \n",
       "3              0.0      0.0             0.0  ...           0.0    0.0   \n",
       "4              0.0      0.0             0.0  ...           0.0    0.0   \n",
       "...            ...      ...             ...  ...           ...    ...   \n",
       "36468          0.0      0.0             0.0  ...           0.0    0.0   \n",
       "36469          0.0      0.0             0.0  ...           0.0    0.0   \n",
       "36470          0.0      0.0             0.0  ...           0.0    0.0   \n",
       "36471          0.0      0.0             0.0  ...           0.0    0.0   \n",
       "36472          0.0      0.0             0.0  ...           0.0    0.0   \n",
       "\n",
       "       influent  elevating  universal  chase  fixedly  creosote  bat  lumber  \n",
       "0           0.0        0.0        0.0    0.0      0.0       0.0  0.0     0.0  \n",
       "1           0.0        0.0        0.0    0.0      0.0       0.0  0.0     0.0  \n",
       "2           0.0        0.0        0.0    0.0      0.0       0.0  0.0     0.0  \n",
       "3           0.0        0.0        0.0    0.0      0.0       0.0  0.0     0.0  \n",
       "4           0.0        0.0        0.0    0.0      0.0       0.0  0.0     0.0  \n",
       "...         ...        ...        ...    ...      ...       ...  ...     ...  \n",
       "36468       0.0        0.0        0.0    0.0      0.0       0.0  0.0     0.0  \n",
       "36469       0.0        0.0        0.0    0.0      0.0       0.0  0.0     0.0  \n",
       "36470       0.0        0.0        0.0    0.0      0.0       0.0  0.0     0.0  \n",
       "36471       0.0        0.0        0.0    0.0      0.0       0.0  0.0     0.0  \n",
       "36472       0.0        0.0        0.0    0.0      0.0       0.0  0.0     0.0  \n",
       "\n",
       "[36473 rows x 7694 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1d24d72e-435e-4861-bd80-bdac9a8c66fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abatement'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7410c8e5-fbd5-419a-8816-88e72c46a31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abatement pollution furniture domestic article appliance coffee mill spice mill suction cleaner general'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_title_combined[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d82e8995-5c11-4f81-a2e8-6f728a4fd8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_test = anchor_tfidf.iloc[0,:]\n",
    "combined_test = combined_tfidf.iloc[0,:]\n",
    "anchor_testarray = anchor_test.to_numpy()\n",
    "combined_testarray = combined_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "84967b21-af89-49f5-9386-a6bec92d34b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_testarray = anchor_testarray.reshape(1, -1)\n",
    "combined_testarray = combined_testarray.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9498e7e0-1d51-4598-b116-479ad6f83b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33717669]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cosine_sum = cosine_similarity(anchor_testarray, combined_testarray)\n",
    "test_cosine_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abb7523-360b-4c56-a9ae-227e980b4c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual similarity score = 0.5\n",
    "# Cosine similarity score = 0.3372"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46071c85-e4ea-4421-bf8b-fafd253779eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "577a0218-42a9-43a7-a9c4-3e0621368f0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Calculate cosine similarity between all patent anchors and combined target/titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1acfcb7f-9135-437e-a5f7-759487e65b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the large tfidf matrix into two separate matrices\n",
    "    # anchor_tfidf = anchor matrix\n",
    "    # combined_tfidf = target/title matrix\n",
    "anchor_tfidf = tfidf_matrix.iloc[0:36473,:]\n",
    "combined_tfidf = tfidf_matrix.iloc[36473:,:]\n",
    "combined_tfidf = combined_tfidf.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "93d3e06f-3af0-4741-a1e8-62ca06513e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to round output to nearest quarter decimal for submission\n",
    "def quarter_round(cosine_list, round_val):\n",
    "    cosine_round = []\n",
    "    for num in cosine_list:\n",
    "        num_rounded = round(num/round_val) * round_val\n",
    "        cosine_round.append(num_rounded)\n",
    "    return cosine_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "52727ee1-93ab-4529-b96a-c3d5bcaa110c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abatement    1.0\n",
       "abnormal     0.0\n",
       "position     0.0\n",
       "absorbent    0.0\n",
       "property     0.0\n",
       "            ... \n",
       "chase        0.0\n",
       "fixedly      0.0\n",
       "creosote     0.0\n",
       "bat          0.0\n",
       "lumber       0.0\n",
       "Name: 1, Length: 7694, dtype: float16"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_tfidf.iloc[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4796e1b4-c221-4eff-aa9e-f05eeda97f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_simlist = []\n",
    "for i in range(len(anchor_list)):\n",
    "    anchor_test = anchor_tfidf.iloc[i,:]\n",
    "    combined_test = combined_tfidf.iloc[i,:]\n",
    "    anchor_testarray = anchor_test.to_numpy()\n",
    "    combined_testarray = combined_test.to_numpy()\n",
    "    anchor_testarray = anchor_testarray.reshape(1, -1)\n",
    "    combined_testarray = combined_testarray.reshape(1, -1)\n",
    "    semantic_cosine = cosine_similarity(anchor_testarray, combined_testarray)\n",
    "    cosine_simlist.append(semantic_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b8e3ed33-1489-4972-adca-2a1ec17054df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.33717669]]),\n",
       " array([[0.]]),\n",
       " array([[0.]]),\n",
       " array([[0.]]),\n",
       " array([[0.]]),\n",
       " array([[0.]]),\n",
       " array([[0.]]),\n",
       " array([[0.]]),\n",
       " array([[0.]]),\n",
       " array([[0.]])]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_simlist[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "52044242-9037-4d5a-8649-6e05647b144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_list = []\n",
    "for i in range(len(cosine_simlist)):\n",
    "    # test_list = np.array2string(cosine_simlist[i][0][0])\n",
    "    value = cosine_simlist[i][0][0]\n",
    "    cosine_list.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f1b95d8c-2a92-48d9-b69a-b5619e7e8b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3371766931452356, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_list[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "394944cb-01ae-4a7d-96a5-d1823880ef4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9256036652485101"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(cosine_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "29f1e239-6df3-4564-a0ed-77972078d048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should not need this\n",
    "# min(cosine_list) = 0\n",
    "'''cosine_positive = []\n",
    "for val in cosine_list:\n",
    "    pos_val = val + 1\n",
    "    cosine_positive.append(pos_val)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "60c8d25e-d728-498e-b5dd-b6cad328757d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3371766931452356"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(cosine_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0fc0cd07-d051-4e1d-be32-bc004f7639ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33717669]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# round each of the scores to the nearest quarter value\n",
    "score_rounded = quarter_round(cosine_positive, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8add70e-1ba3-4505-8d3a-4428381834b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_rounded[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4ade94-4fd9-4f39-a131-fba94b53c373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ea116a8a-dfc1-4030-abf6-1c500cc5c93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abatement of pollution</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7b9652b17b68b7a4</td>\n",
       "      <td>abatement</td>\n",
       "      <td>act of abating</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36d72442aefd8232</td>\n",
       "      <td>abatement</td>\n",
       "      <td>active catalyst</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5296b0c19e1ce60e</td>\n",
       "      <td>abatement</td>\n",
       "      <td>eliminating process</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54c1e3b9184cb5b6</td>\n",
       "      <td>abatement</td>\n",
       "      <td>forest region</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36468</th>\n",
       "      <td>8e1386cbefd7f245</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden article</td>\n",
       "      <td>B44</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36469</th>\n",
       "      <td>42d9e032d1cd3242</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden box</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36470</th>\n",
       "      <td>208654ccb9e14fa3</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden handle</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36471</th>\n",
       "      <td>756ec035e694722b</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden material</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36472</th>\n",
       "      <td>8d135da0b55b8c88</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden substrate</td>\n",
       "      <td>B44</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36473 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id        anchor                  target context  score\n",
       "0      37d61fd2272659b1     abatement  abatement of pollution     A47   0.50\n",
       "1      7b9652b17b68b7a4     abatement          act of abating     A47   0.75\n",
       "2      36d72442aefd8232     abatement         active catalyst     A47   0.25\n",
       "3      5296b0c19e1ce60e     abatement     eliminating process     A47   0.50\n",
       "4      54c1e3b9184cb5b6     abatement           forest region     A47   0.00\n",
       "...                 ...           ...                     ...     ...    ...\n",
       "36468  8e1386cbefd7f245  wood article          wooden article     B44   1.00\n",
       "36469  42d9e032d1cd3242  wood article              wooden box     B44   0.50\n",
       "36470  208654ccb9e14fa3  wood article           wooden handle     B44   0.50\n",
       "36471  756ec035e694722b  wood article         wooden material     B44   0.75\n",
       "36472  8d135da0b55b8c88  wood article        wooden substrate     B44   0.50\n",
       "\n",
       "[36473 rows x 5 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patent_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0303a3e0-c14c-4ed4-8719-ab312b464350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d8b9e1-e25e-4ffa-a017-f08af250d953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import os\n",
    "\n",
    "client = storage.Client()\n",
    "bucket = client.get_bucket('cliffm_uspto_kaggle_data')\n",
    "bucket.blob('tfidf_matrix.parquet.gzip').upload_from_string(tfidf_matrix.to_parquet(), 'parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6084aba-ff4c-4b93-8046-87999caa8b50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898fdc51-9fa2-4a00-b526-c742620dc137",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = pd.read_csv('/home/jupyter/uspto_analysis/tfidf_matrix.csv')\n",
    "tf_idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "90fb7674-c1a0-4f98-bf8d-1b1c07e48a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.7990465392774274), (2, 0.6012691810402117)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tfidf[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0c0c5742-97b5-4937-a441-3e1a8e485aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72946"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5bf18e6d-7bf2-4946-9d32-5fabe43e15af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abnormal', 'position']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_patent_process[71]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "36bb16d3-11ec-4500-8b2a-0272cc25e16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abnormal', 'placement', 'weaving']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_patent_process[36546]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63bff26-aeae-457e-acb0-9284eaa27329",
   "metadata": {},
   "source": [
    "## Testing the model on a few sample patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ab109caa-eb7f-4fbb-95e8-1e61cf6cca76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abnormal', 'breathing', 'weaving']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_patent_process[36544]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5e076138-ee6d-445a-83c0-6dfad12abf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test cosine similarity\n",
    "    # anchor 1 = abnormal position\n",
    "    # target/title 1 = abnormal breathing/weaving\n",
    "    # score 1 = 0\n",
    "    # anchor 2 = abnormal position\n",
    "    # target/title 2 = abnormal placement/weaving\n",
    "    # score 2 = 0.75\n",
    "train_anchor = corpus_tfidf[71]\n",
    "train_combined = corpus_tfidf[36544]\n",
    "train_anchor2 = corpus_tfidf[73]\n",
    "train_combined2 = corpus_tfidf[36546]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "04562f58-c938-4e10-bf31-e2f1439ce99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.7990465392774274), (2, 0.6012691810402117)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f1aa0a3b-a896-4dc5-b601-75a87ee75f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.5027760784033785),\n",
       " (1096, 0.7413125030310371),\n",
       " (1097, 0.44460318019013145)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1a9eb89a-4e21-458e-a2fe-c502587db576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97838527, 0.78165408, 0.78148496],\n",
       "       [0.98493007, 0.95785337, 0.95777547]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_distance1 = cosine_similarity(train_anchor, train_combined)\n",
    "cos_distance1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2adc25ca-1f89-4144-a963-8f3ec1750ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97703633, 0.78148093, 0.78165835],\n",
       "       [0.98602106, 0.95777361, 0.95785534]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_distance2 = cosine_similarity(train_anchor2, train_combined2)\n",
    "cos_distance2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302b5125-1b56-4c74-98c8-f205d8f835b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87bd3843-f5da-4383-9337-791e4818944a",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a253c1d3-fcdb-47fb-9084-caf906851e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the gensim tfidf model on the corpus\n",
    "tfidf2 = models.TfidfModel(corpus, smartirs = 'ntc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df68da5-7a29-4eb6-b4a8-696f67960618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the word ids and their frequencies in the tfidf model\n",
    "for doc in tfidf2[corpus]:\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
